{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018ee520",
   "metadata": {},
   "source": [
    "# 12 Beta meta-integration cross-omics\n",
    "\n",
    "**Origin:** `1_2_beta_merged_meta.ipynb`  \n",
    "**This annotated version was generated on:** 2025-10-13 06:41\n",
    "\n",
    "**What this notebook does (high level):**  \n",
    "- Merge MR-derived effect sizes (β) across modalities and meta-analyze to produce unified causal weights per gene.\n",
    "\n",
    "**How to use:**  \n",
    "1. Review the markdown notes before each code cell.  \n",
    "2. Adjust input/output paths as needed for your environment.  \n",
    "3. Run cell-by-cell to reproduce artifacts for downstream steps.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ee710",
   "metadata": {},
   "source": [
    "**Step 1:** Load tabular data (summary stats / annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80124a2c-f7e4-4612-bd91-d9f6ef9d3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2, norm\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def ivw_fixed(b, se):\n",
    "    w = 1.0 / (se**2)\n",
    "    beta = np.sum(w*b) / np.sum(w)\n",
    "    se_pooled = np.sqrt(1.0 / np.sum(w))\n",
    "    z = beta / se_pooled\n",
    "    p = 2*norm.sf(abs(z))\n",
    "    return beta, se_pooled, z, p\n",
    "\n",
    "def heterogeneity(b, se, beta_fe):\n",
    "    w = 1.0 / (se**2)\n",
    "    q = np.sum(w * (b - beta_fe)**2)\n",
    "    k = len(b)\n",
    "    df = k - 1\n",
    "    p_q = 1 - chi2.cdf(q, df) if df > 0 else np.nan\n",
    "    i2 = max(0.0, (q - df) / q) if q > 0 and df > 0 else 0.0\n",
    "    c = np.sum(w) - (np.sum(w**2) / np.sum(w))\n",
    "    tau2 = max(0.0, (q - df) / c) if c > 0 and df > 0 else 0.0\n",
    "    return q, df, p_q, i2, tau2\n",
    "\n",
    "def ivw_random_dl(b, se):\n",
    "    beta_fe, se_fe, _, _, = ivw_fixed(b, se)\n",
    "    q, df, _, _, tau2 = heterogeneity(b, se, beta_fe)\n",
    "    w_star = 1.0 / (se**2 + tau2)\n",
    "    beta = np.sum(w_star*b) / np.sum(w_star)\n",
    "    se_pooled = np.sqrt(1.0 / np.sum(w_star))\n",
    "    z = beta / se_pooled\n",
    "    p = 2*norm.sf(abs(z))\n",
    "    return beta, se_pooled, z, p, q, df, tau2\n",
    "\n",
    "def meta_within_platform(df_list, labels, use_random=False, min_studies=1):\n",
    "    # stack and pool within each platform\n",
    "    outs = []\n",
    "    for lab, df in zip(labels, df_list):\n",
    "        req = {\"gene\",\"weighted_beta\",\"weighted_se\"}\n",
    "        if not req.issubset(df.columns):\n",
    "            raise ValueError(f\"Missing columns in {lab}: need {req}\")\n",
    "        d = df[[\"gene\",\"weighted_beta\",\"weighted_se\"]].rename(\n",
    "            columns={\"weighted_beta\":\"beta\",\"weighted_se\":\"se\"}\n",
    "        ).dropna()\n",
    "        d[\"study\"] = lab\n",
    "        outs.append(d)\n",
    "    long = pd.concat(outs, ignore_index=True)\n",
    "\n",
    "    # group by platform family\n",
    "    platform = np.array([\"eqtl\",\"eqtl\",\"pqtl\",\"pqtl\"])  # map your 4 inputs\n",
    "    platform_map = dict(zip(labels, platform))\n",
    "\n",
    "    pooled = []\n",
    "    for (g, fam), sub in long.groupby([ \"gene\", long[\"study\"].map(platform_map) ]):\n",
    "        b = sub[\"beta\"].to_numpy(float)\n",
    "        s = sub[\"se\"].to_numpy(float)\n",
    "        if len(b) < min_studies:\n",
    "            # keep singleton as-is\n",
    "            pooled.append({\"gene\": g, \"platform\": fam,\n",
    "                           \"beta\": b[0], \"se\": s[0], \"k\": len(b)})\n",
    "            continue\n",
    "        if use_random and len(b) >= 2:\n",
    "            beta, se, z, p, q, df, tau2 = ivw_random_dl(b, s)\n",
    "        else:\n",
    "            beta, se, z, p = ivw_fixed(b, s)\n",
    "        pooled.append({\"gene\": g, \"platform\": fam,\n",
    "                       \"beta\": beta, \"se\": se, \"k\": len(b)})\n",
    "    pooled = pd.DataFrame(pooled)\n",
    "    # pivot to eqtl/pqtl columns\n",
    "    wide = pooled.pivot(index=\"gene\", columns=\"platform\", values=[\"beta\",\"se\",\"k\"])\n",
    "    # flatten columns\n",
    "    wide.columns = [f\"{a}_{b}\" for a,b in wide.columns]\n",
    "    wide = wide.reset_index()\n",
    "    return wide\n",
    "\n",
    "# ---- Deming regression to calibrate pqtl→eqtl (errors-in-variables) ----\n",
    "def deming_fit(x, y, se_x=None, se_y=None):\n",
    "    \"\"\"\n",
    "    Fit y = a + b x with errors in both x and y.\n",
    "    lambda = Var(e_x)/Var(e_y). We approximate with mean(se_x^2)/mean(se_y^2).\n",
    "    Returns a, b. (Uncertainty of a,b ignored here for simplicity.)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x); y = np.asarray(y)\n",
    "    xbar, ybar = x.mean(), y.mean()\n",
    "    X = x - xbar; Y = y - ybar\n",
    "    Sxx = np.sum(X*X) / (len(x)-1)\n",
    "    Syy = np.sum(Y*Y) / (len(y)-1)\n",
    "    Sxy = np.sum(X*Y) / (len(x)-1)\n",
    "    if se_x is None or se_y is None:\n",
    "        lam = 1.0\n",
    "    else:\n",
    "        lam = np.nanmean(se_x**2) / np.nanmean(se_y**2)\n",
    "        if not np.isfinite(lam) or lam <= 0: lam = 1.0\n",
    "    # Deming slope\n",
    "    delta = (Syy - lam*Sxx)\n",
    "    b = (delta + np.sqrt(delta**2 + 4*lam*Sxy**2)) / (2*Sxy)\n",
    "    a = ybar - b*xbar\n",
    "    return a, b\n",
    "\n",
    "def apply_linear_transform(beta, se, a, b):\n",
    "    \"\"\"\n",
    "    Map y = a + b*x; propagate SE ignoring (a,b) uncertainty.\n",
    "    Var(y) ≈ b^2 Var(x) → se_y = |b| se_x.\n",
    "    \"\"\"\n",
    "    beta_t = a + b*beta\n",
    "    se_t = np.abs(b) * se\n",
    "    return beta_t, se_t\n",
    "\n",
    "# ---------- main wrapper ----------\n",
    "def cross_modal_meta(\n",
    "    eqtlgen_path, gtex_path, decode_path, ukbppp_path,\n",
    "    use_random_within=False,\n",
    "    require_overlap_for_calibration=True\n",
    "):\n",
    "    labels = [\"eqtlgen\",\"gtex\",\"decode\",\"ukbppp\"]\n",
    "    dfs = [pd.read_csv(p, sep=\"\\t\") for p in [eqtlgen_path, gtex_path, decode_path, ukbppp_path]]\n",
    "\n",
    "    # 1) within-modality pooling\n",
    "    wide = meta_within_platform(dfs, labels, use_random=use_random_within, min_studies=1)\n",
    "    # Now we may have columns: beta_eqtl, se_eqtl, beta_pqtl, se_pqtl (some missing)\n",
    "    # Create concise columns\n",
    "    if \"beta_eqtl\" not in wide.columns:\n",
    "        wide[\"beta_eqtl\"] = np.nan; wide[\"se_eqtl\"] = np.nan\n",
    "    if \"beta_pqtl\" not in wide.columns:\n",
    "        wide[\"beta_pqtl\"] = np.nan; wide[\"se_pqtl\"] = np.nan\n",
    "\n",
    "    # 2) calibration using genes with both\n",
    "    both = wide.dropna(subset=[\"beta_eqtl\",\"se_eqtl\",\"beta_pqtl\",\"se_pqtl\"])\n",
    "    if len(both) >= 10:  # need some signal to calibrate\n",
    "        a, b = deming_fit(\n",
    "            x=both[\"beta_pqtl\"].values,\n",
    "            y=both[\"beta_eqtl\"].values,\n",
    "            se_x=both[\"se_pqtl\"].values,\n",
    "            se_y=both[\"se_eqtl\"].values\n",
    "        )\n",
    "    else:\n",
    "        # fallback: identity mapping\n",
    "        a, b = 0.0, 1.0\n",
    "\n",
    "    # Option A: map everything onto the eQTL scale\n",
    "    beta_eqtl = wide[\"beta_eqtl\"].copy()\n",
    "    se_eqtl = wide[\"se_eqtl\"].copy()\n",
    "\n",
    "    # transform pQTL-only to eQTL scale\n",
    "    mask_p_only = beta_eqtl.isna() & wide[\"beta_pqtl\"].notna()\n",
    "    if mask_p_only.any():\n",
    "        t_beta, t_se = apply_linear_transform(\n",
    "            beta=wide.loc[mask_p_only, \"beta_pqtl\"].values,\n",
    "            se=wide.loc[mask_p_only, \"se_pqtl\"].values,\n",
    "            a=a, b=b\n",
    "        )\n",
    "        beta_eqtl.loc[mask_p_only] = t_beta\n",
    "        se_eqtl.loc[mask_p_only] = t_se\n",
    "\n",
    "    # 3) final per-gene meta on the eQTL scale (use FE here; switch to RE if you like)\n",
    "    meta_rows = []\n",
    "    for i, row in wide.iterrows():\n",
    "        g = row[\"gene\"]\n",
    "        estimates = []\n",
    "        ses = []\n",
    "        labels_used = []\n",
    "        # If we have original eQTL pooled:\n",
    "        if pd.notna(row.get(\"beta_eqtl\", np.nan)) and pd.notna(row.get(\"se_eqtl\", np.nan)):\n",
    "            estimates.append(row[\"beta_eqtl\"]); ses.append(row[\"se_eqtl\"]); labels_used.append(\"eQTL\")\n",
    "        # If we also had original pQTL, transform it too and include (gives 2-study meta)\n",
    "        if pd.notna(row.get(\"beta_pqtl\", np.nan)) and pd.notna(row.get(\"se_pqtl\", np.nan)):\n",
    "            b_t, s_t = apply_linear_transform(row[\"beta_pqtl\"], row[\"se_pqtl\"], a, b)\n",
    "            estimates.append(b_t); ses.append(s_t); labels_used.append(\"pQTL→eQTLscale\")\n",
    "\n",
    "        estimates = np.array(estimates, float)\n",
    "        ses = np.array(ses, float)\n",
    "\n",
    "        if len(estimates) == 0:\n",
    "            continue  # no info\n",
    "        elif len(estimates) == 1:\n",
    "            # keep singleton\n",
    "            meta_beta, meta_se = estimates[0], ses[0]\n",
    "            k_final = 1\n",
    "        else:\n",
    "            meta_beta, meta_se, _, _ = ivw_fixed(estimates, ses)\n",
    "            k_final = len(estimates)\n",
    "\n",
    "        meta_rows.append({\n",
    "            \"gene\": g,\n",
    "            \"meta_beta_common\": meta_beta,\n",
    "            \"meta_se_common\": meta_se,\n",
    "            \"k_final\": k_final,\n",
    "            \"used\": \";\".join(labels_used),\n",
    "            \"a_calib\": a,\n",
    "            \"b_calib\": b\n",
    "        })\n",
    "\n",
    "    meta_final = pd.DataFrame(meta_rows).sort_values(\"gene\").reset_index(drop=True)\n",
    "    return meta_final\n",
    "\n",
    "# ----------- usage -----------\n",
    "\n",
    "# beta estates from instruments within DHS \n",
    "eqtlgen_path = '/mnt/f/10_osteo_MR/results_mr_ptrs/PTRS/bulk_eqtlgen_weighted_beta_table.tsv'\n",
    "gtex_path    = '/mnt/f/10_osteo_MR/results_mr_ptrs/PTRS/bulk_gtex_weighted_beta_table.tsv'\n",
    "decode_path  = '/mnt/f/10_osteo_MR/results_mr_ptrs/PTRS/bulk_pqtl_decode_weighted_beta_table.tsv'\n",
    "ukbppp_path  = '/mnt/f/10_osteo_MR/results_mr_ptrs/PTRS/bulk_pqtl_ukbppp_weighted_beta_table.tsv'\n",
    "\n",
    "\n",
    "\n",
    "meta_final = cross_modal_meta(eqtlgen_path, gtex_path, decode_path, ukbppp_path,\n",
    "                              use_random_within=False)\n",
    "meta_final.to_csv('/mnt/f/10_osteo_MR/results_mr_ptrs/PTRS/bulk_crossmodal_meta_beta.tsv',\n",
    "                  sep='\\t', index=False)\n",
    "\n",
    "# For PTRS weights:\n",
    "meta_beta = meta_final[[\"gene\",\"meta_beta_common\"]].rename(columns={\"meta_beta_common\":\"weighted_beta\"})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
