{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4de00a",
   "metadata": {},
   "source": [
    "# 62 Drug prioritization GNN\n",
    "\n",
    "**Origin:** `6_2_drug_prioritization_GNN_.ipynb`  \n",
    "**Annotated on:** 2025-10-13 06:45\n",
    "\n",
    "**High-level objective:**  \n",
    "- Train GNNs (GCN/GAT) over module graphs to impute/propagate MR betas; export predictions for DRS/TRS.\n",
    "\n",
    "**Notes:**  \n",
    "- These comments are language-agnostic and focus on intent, inputs, and outputs.  \n",
    "- Adjust hard-coded paths if needed; prefer `/results_*` for derived artifacts.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ba5c5",
   "metadata": {},
   "source": [
    "**Step 1:** Community detection / resolution sweep on the PPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a965562-f7b9-4f72-a607-b64602f7b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unit tests for gnn_from_graphml.py\n",
    "Run with: pytest -q\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "from gnn_from_graphml import (\n",
    "    build_data_from_graphml,\n",
    "    build_model,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "def _make_tiny_graphml(tmpdir: str, fname: str = \"toy.graphml\") -> str:\n",
    "    \"\"\"\n",
    "    Create a tiny undirected graph with:\n",
    "      nodes: A(community=0, beta=0.4), B(0, beta=-0.2), C(1, beta=NaN), D(1, beta=NaN)\n",
    "      edges: A-B (w=1.0), B-C (w=0.5), C-D (w=1.0)\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    G.add_node(\"A\", community=0, beta=0.4)\n",
    "    G.add_node(\"B\", community=0, beta=-0.2)\n",
    "    G.add_node(\"C\", community=1, beta=float(\"nan\"))\n",
    "    G.add_node(\"D\", community=1, beta=float(\"nan\"))\n",
    "\n",
    "    G.add_edge(\"A\", \"B\", weight=1.0)\n",
    "    G.add_edge(\"B\", \"C\", weight=0.5)\n",
    "    G.add_edge(\"C\", \"D\", weight=1.0)\n",
    "\n",
    "    path = os.path.join(tmpdir, fname)\n",
    "    nx.write_graphml(G, path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def test_build_data_from_graphml_total():\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        gml = _make_tiny_graphml(td)\n",
    "        data, idx2gene, gene2idx = build_data_from_graphml(\n",
    "            gml,\n",
    "            submodule=None,\n",
    "            add_degree_features=True,\n",
    "            use_label_as_feat=True,\n",
    "            add_community_feature=True,\n",
    "        )\n",
    "        # nodes\n",
    "        assert data.x.shape[0] == 4\n",
    "        # features: degree(1) + prior(1) + is_label(1) + community one-hot (max id=1 => 2 cols) => 5 total\n",
    "        assert data.x.shape[1] == 5\n",
    "        # labels present on A,B only\n",
    "        assert int(data.has_label.sum().item()) == 2\n",
    "        # edge_index should exist and be even (undirected + self-loops)\n",
    "        assert data.edge_index.shape[0] == 2\n",
    "        assert data.edge_attr.shape[0] == data.edge_index.shape[1]\n",
    "\n",
    "\n",
    "def test_build_data_from_graphml_submodule_filter():\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        gml = _make_tiny_graphml(td)\n",
    "        # take submodule 1 (C,D)\n",
    "        data, idx2gene, gene2idx = build_data_from_graphml(\n",
    "            gml,\n",
    "            submodule=1,\n",
    "            add_degree_features=True,\n",
    "            use_label_as_feat=True,\n",
    "            add_community_feature=False,\n",
    "        )\n",
    "        assert data.x.shape[0] == 2  # only C and D\n",
    "        # no labels in this submodule (C,D have NaN beta)\n",
    "        assert int(data.has_label.sum().item()) == 0  # will raise if used in training without labels\n",
    "\n",
    "\n",
    "def test_trainer_split_and_train_minimal_gcn():\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        gml = _make_tiny_graphml(td)\n",
    "        data, idx2gene, gene2idx = build_data_from_graphml(\n",
    "            gml,\n",
    "            submodule=None,\n",
    "            add_degree_features=True,\n",
    "            use_label_as_feat=True,\n",
    "            add_community_feature=False,\n",
    "        )\n",
    "        # Ensure at least 2 labeled nodes for split (A,B)\n",
    "        assert int(data.has_label.sum().item()) >= 2\n",
    "\n",
    "        # Build minimal GCN\n",
    "        in_dim = data.x.shape[1]\n",
    "        model = build_model(\"GCN\", in_dim, {\"hidden\": 16, \"layers\": 2, \"dropout\": 0.1})\n",
    "        trainer = Trainer(data, model, lr=5e-3, weight_decay=0.0, patience=20)\n",
    "\n",
    "        set_seed(123)\n",
    "        train_mask, val_mask = trainer.split_masks(val_size=0.5, seed=123)\n",
    "\n",
    "        # Masks should be subset of has_label\n",
    "        assert bool((train_mask & (~data.has_label)).any().item()) is False\n",
    "        assert bool((val_mask   & (~data.has_label)).any().item()) is False\n",
    "\n",
    "        # Train briefly; just ensure it runs and produces predictions\n",
    "        trainer.train(epochs=50, verbose=False)\n",
    "        pred = trainer.predict_all()\n",
    "        assert isinstance(pred, torch.Tensor)\n",
    "        assert pred.numel() == data.x.shape[0]\n",
    "\n",
    "\n",
    "def test_trainer_with_gat():\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        gml = _make_tiny_graphml(td)\n",
    "        data, idx2gene, gene2idx = build_data_from_graphml(\n",
    "            gml,\n",
    "            submodule=None,\n",
    "            add_degree_features=True,\n",
    "            use_label_as_feat=True,\n",
    "            add_community_feature=False,\n",
    "        )\n",
    "        in_dim = data.x.shape[1]\n",
    "        model = build_model(\"GAT\", in_dim, {\"hidden\": 16, \"layers\": 2, \"heads\": 2, \"dropout\": 0.1, \"attn_dropout\": 0.0})\n",
    "        trainer = Trainer(data, model, lr=1e-3, weight_decay=0.0, patience=10)\n",
    "        trainer.split_masks(val_size=0.5, seed=7)\n",
    "        trainer.train(epochs=30, verbose=False)\n",
    "        df = trainer.export_predictions(os.path.join(td, \"pred.tsv\"))\n",
    "        assert df.shape[0] == data.x.shape[0]\n",
    "        assert {\"gene\", \"pred_beta\", \"is_labeled\", \"true_beta\"}.issubset(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24771b3b",
   "metadata": {},
   "source": [
    "**Step 2:** Graph construction or GNN modeling (GCN/GAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a7394cd-6f43-469f-b26d-4e5fb10981dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 | train 0.309268 | val 0.061370\n",
      "Epoch   25 | train 0.141663 | val 0.052051\n",
      "Epoch   50 | train 0.086361 | val 0.033164\n",
      "Epoch   75 | train 0.052538 | val 0.026549\n",
      "Epoch  100 | train 0.051623 | val 0.024798\n",
      "Epoch  125 | train 0.038426 | val 0.025476\n",
      "Epoch  150 | train 0.051707 | val 0.024737\n",
      "Epoch  175 | train 0.078164 | val 0.024373\n",
      "Epoch  200 | train 0.043249 | val 0.024210\n",
      "Epoch  225 | train 0.035632 | val 0.024167\n",
      "Epoch  250 | train 0.035349 | val 0.024500\n",
      "Epoch  275 | train 0.033880 | val 0.023448\n",
      "Epoch  300 | train 0.039681 | val 0.023087\n",
      "Epoch  325 | train 0.028943 | val 0.022000\n",
      "Epoch  350 | train 0.023006 | val 0.021761\n",
      "Epoch  375 | train 0.025155 | val 0.027420\n",
      "Epoch  400 | train 0.032799 | val 0.027870\n",
      "Epoch  425 | train 0.024576 | val 0.025586\n",
      "Epoch  450 | train 0.020037 | val 0.022637\n",
      "Epoch  475 | train 0.019316 | val 0.024492\n",
      "Epoch  500 | train 0.025133 | val 0.022586\n",
      "Early stopping at epoch 520 (best val=0.020520)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from gnn_from_graphml import train_from_graphml\n",
    "\n",
    "trainer, preds = train_from_graphml(\n",
    "    graphml_path=\"/mnt/f/10_osteo_MR/results_network/largest_causal_subnet_A2_a6_g0.001832981/causal_modules.graphml\",\n",
    "    outdir=\"/mnt/f/10_osteo_MR/gnn_from_graphml_runs\",\n",
    "    submodule=None,        # or an int 0..12\n",
    "    model_type=\"GAT\",\n",
    "    hidden=128,\n",
    "    layers=3,\n",
    "    heads=4,\n",
    "    dropout=0.3,\n",
    "    attn_dropout=0.1,\n",
    "    lr=1e-3,\n",
    "    weight_decay=5e-4,\n",
    "    epochs=600,\n",
    "    patience=80,\n",
    "    val_size=0.2,\n",
    "    add_degree_features=True,\n",
    "    use_label_as_feat=True,\n",
    "    add_community_feature=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614b54a",
   "metadata": {},
   "source": [
    "**Step 3:** Load network or tabular inputs (PPI/GraphML/TSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e14ad35c-72c1-47aa-bd8c-86fed448bc97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Training TOTAL causal module ==\n",
      "Epoch    1 | train 0.309268 | val 0.061352\n",
      "Epoch   25 | train 0.132905 | val 0.050230\n",
      "Epoch   50 | train 0.071826 | val 0.036703\n",
      "Epoch   75 | train 0.051588 | val 0.028961\n",
      "Epoch  100 | train 0.049184 | val 0.024228\n",
      "Epoch  125 | train 0.036236 | val 0.025325\n",
      "Epoch  150 | train 0.049714 | val 0.023745\n",
      "Epoch  175 | train 0.084519 | val 0.023178\n",
      "Epoch  200 | train 0.047027 | val 0.023093\n",
      "Epoch  225 | train 0.037955 | val 0.023044\n",
      "Epoch  250 | train 0.036443 | val 0.023222\n",
      "Epoch  275 | train 0.034772 | val 0.022156\n",
      "Epoch  300 | train 0.035943 | val 0.022067\n",
      "Epoch  325 | train 0.027847 | val 0.021777\n",
      "Epoch  350 | train 0.022879 | val 0.021960\n",
      "Epoch  375 | train 0.024185 | val 0.026455\n",
      "Early stopping at epoch 399 (best val=0.020910)\n",
      "Submodules to run: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "\n",
      "== Submodule 0 ==\n",
      "Nodes=450  Labeled=41\n",
      "Epoch    1 | train 0.461596 | val 0.103306\n",
      "Epoch   25 | train 0.174893 | val 0.054353\n",
      "Epoch   50 | train 0.146266 | val 0.074039\n",
      "Epoch   75 | train 0.094355 | val 0.057297\n",
      "Epoch  100 | train 0.077936 | val 0.044734\n",
      "Early stopping at epoch 100 (best val=0.028086)\n",
      "\n",
      "== Submodule 1 ==\n",
      "Nodes=360  Labeled=23\n",
      "Epoch    1 | train 0.099379 | val 0.050813\n",
      "Epoch   25 | train 0.048633 | val 0.064218\n",
      "Epoch   50 | train 0.052237 | val 0.060005\n",
      "Epoch   75 | train 0.043820 | val 0.035767\n",
      "Epoch  100 | train 0.050414 | val 0.090409\n",
      "Epoch  125 | train 0.050033 | val 0.053108\n",
      "Epoch  150 | train 0.026140 | val 0.063831\n",
      "Early stopping at epoch 157 (best val=0.030708)\n",
      "\n",
      "== Submodule 2 ==\n",
      "Nodes=325  Labeled=55\n",
      "Epoch    1 | train 0.217721 | val 0.017188\n",
      "Epoch   25 | train 0.092608 | val 0.023334\n",
      "Epoch   50 | train 0.047883 | val 0.043276\n",
      "Epoch   75 | train 0.046579 | val 0.013347\n",
      "Epoch  100 | train 0.050703 | val 0.012631\n",
      "Epoch  125 | train 0.057701 | val 0.014650\n",
      "Epoch  150 | train 0.033396 | val 0.014477\n",
      "Early stopping at epoch 168 (best val=0.011979)\n",
      "\n",
      "== Submodule 3 ==\n",
      "Nodes=288  Labeled=38\n",
      "Epoch    1 | train 0.785790 | val 0.109323\n",
      "Epoch   25 | train 0.285050 | val 0.044414\n",
      "Epoch   50 | train 0.481415 | val 0.081390\n",
      "Epoch   75 | train 0.091038 | val 0.017511\n",
      "Early stopping at epoch 89 (best val=0.015628)\n",
      "\n",
      "== Submodule 4 ==\n",
      "Nodes=242  Labeled=29\n",
      "Epoch    1 | train 0.566677 | val 0.044696\n",
      "Epoch   25 | train 0.122475 | val 0.155211\n",
      "Epoch   50 | train 0.065515 | val 0.023688\n",
      "Epoch   75 | train 0.060105 | val 0.022537\n",
      "Epoch  100 | train 0.063296 | val 0.041134\n",
      "Epoch  125 | train 0.078784 | val 0.044041\n",
      "Early stopping at epoch 133 (best val=0.019703)\n",
      "\n",
      "== Submodule 5 ==\n",
      "Nodes=230  Labeled=17\n",
      "Epoch    1 | train 0.503900 | val 0.056763\n",
      "Epoch   25 | train 0.367801 | val 0.079678\n",
      "Epoch   50 | train 0.338715 | val 0.037035\n",
      "Epoch   75 | train 0.185424 | val 0.066332\n",
      "Epoch  100 | train 0.087534 | val 0.066307\n",
      "Epoch  125 | train 0.061451 | val 0.061458\n",
      "Early stopping at epoch 127 (best val=0.032395)\n",
      "\n",
      "== Submodule 6 ==\n",
      "Nodes=227  Labeled=22\n",
      "Epoch    1 | train 0.208538 | val 0.101217\n",
      "Epoch   25 | train 0.216843 | val 0.077167\n",
      "Epoch   50 | train 0.052767 | val 0.092017\n",
      "Epoch   75 | train 0.084848 | val 0.081839\n",
      "Epoch  100 | train 0.035269 | val 0.060550\n",
      "Epoch  125 | train 0.054422 | val 0.065034\n",
      "Epoch  150 | train 0.062741 | val 0.060916\n",
      "Early stopping at epoch 168 (best val=0.050461)\n",
      "\n",
      "== Submodule 7 ==\n",
      "Nodes=206  Labeled=29\n",
      "Epoch    1 | train 0.114058 | val 0.191844\n",
      "Epoch   25 | train 0.129573 | val 0.040970\n",
      "Epoch   50 | train 0.085643 | val 0.034850\n",
      "Epoch   75 | train 0.063331 | val 0.067940\n",
      "Epoch  100 | train 0.069801 | val 0.052326\n",
      "Early stopping at epoch 102 (best val=0.033893)\n",
      "\n",
      "== Submodule 8 ==\n",
      "Nodes=79  Labeled=13\n",
      "Epoch    1 | train 0.128750 | val 0.131827\n",
      "Epoch   25 | train 0.078426 | val 0.044753\n",
      "Epoch   50 | train 0.032160 | val 0.096797\n",
      "Epoch   75 | train 0.034834 | val 0.111462\n",
      "Epoch  100 | train 0.026216 | val 0.054070\n",
      "Epoch  125 | train 0.031209 | val 0.084061\n",
      "Early stopping at epoch 148 (best val=0.038231)\n",
      "\n",
      "== Submodule 9 ==\n",
      "Nodes=46  Labeled=10\n",
      "Epoch    1 | train 0.292383 | val 0.047964\n",
      "Epoch   25 | train 0.072263 | val 0.036644\n",
      "Epoch   50 | train 0.065884 | val 0.036117\n",
      "Epoch   75 | train 0.068357 | val 0.033422\n",
      "Early stopping at epoch 94 (best val=0.024782)\n",
      "\n",
      "== Submodule 10 ==\n",
      "Nodes=14  Labeled=8\n",
      "Epoch    1 | train 0.240225 | val 0.042795\n",
      "Epoch   25 | train 0.092156 | val 0.243281\n",
      "Epoch   50 | train 0.170077 | val 0.051183\n",
      "Epoch   75 | train 0.232566 | val 0.094055\n",
      "Early stopping at epoch 81 (best val=0.042795)\n",
      "\n",
      "== Submodule 11 ==\n",
      "Nodes=3  Labeled=1\n",
      "  Not enough labeled nodes; using TOTAL-model fallback.\n",
      "\n",
      "== Submodule 12 ==\n",
      "  ERROR on submodule 12: Subgraph has zero nodes (submodule filter too strict?).\n",
      "  Fallback failed for submodule 12: Subgraph has zero nodes (submodule filter too strict?).\n",
      "\n",
      "Wrote summary to: /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submodules/GAT_submodules_summary.csv\n",
      "    submodule  n_nodes  n_labeled  trained  val_rmse  \\\n",
      "0           0      450         41     True  0.167589   \n",
      "1           1      360         23     True  0.175238   \n",
      "2           2      325         55     True  0.109448   \n",
      "3           3      288         38     True  0.125014   \n",
      "4           4      242         29     True  0.140368   \n",
      "5           5      230         17     True  0.179986   \n",
      "6           6      227         22     True  0.224635   \n",
      "7           7      206         29     True  0.184100   \n",
      "8           8       79         13     True  0.195529   \n",
      "9           9       46         10     True  0.157422   \n",
      "10         10       14          8     True  0.206869   \n",
      "11         11        3          1    False       NaN   \n",
      "\n",
      "                                             out_path  \n",
      "0   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "1   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "2   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "3   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "4   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "5   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "6   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "7   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "8   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "9   /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "10  /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n",
      "11  /mnt/f/10_osteo_MR/gnn_from_graphml_runs_submo...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Run per-submodule training over communities 0..12.\n",
    "- Trains total-model once (for fallback + comparison).\n",
    "- Trains each submodule; if too few labels, falls back to total predictions.\n",
    "- Writes one TSV per submodule and a summary CSV.\n",
    "\n",
    "Usage (example):\n",
    "  python run_submodules.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "\n",
    "from gnn_from_graphml import (\n",
    "    train_from_graphml,\n",
    "    build_data_from_graphml,\n",
    "    build_model,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "GRAPHML = \"/mnt/f/10_osteo_MR/results_network/largest_causal_subnet_A2_a6_g0.001832981/causal_modules.graphml\"\n",
    "OUTDIR  = \"/mnt/f/10_osteo_MR/gnn_from_graphml_runs_submodules\"\n",
    "\n",
    "# ---- Default model/training params (edit if you like) ----\n",
    "MODEL_TYPE     = \"GAT\"     # \"GAT\" or \"GCN\"\n",
    "HIDDEN         = 128\n",
    "LAYERS         = 3\n",
    "HEADS          = 4\n",
    "DROPOUT        = 0.3\n",
    "ATTN_DROPOUT   = 0.1       # GAT only\n",
    "LR             = 1e-3\n",
    "WEIGHT_DECAY   = 5e-4\n",
    "EPOCHS         = 600\n",
    "PATIENCE       = 80\n",
    "VAL_SIZE       = 0.2\n",
    "SEED           = 42\n",
    "\n",
    "ADD_DEGREE_FEATURES   = True\n",
    "USE_LABEL_AS_FEAT     = True\n",
    "ADD_COMMUNITY_FEATURE = False   # per submodule this is not needed\n",
    "\n",
    "def list_submodules(graphml_path: str, community_attr: str = \"community\") -> List[int]:\n",
    "    G = nx.read_graphml(graphml_path)\n",
    "    c = sorted({int(d.get(community_attr, -1)) for _, d in G.nodes(data=True)})\n",
    "    # Filter out negatives if present\n",
    "    return [x for x in c if x >= 0]\n",
    "\n",
    "def _compute_val_rmse(trainer: Trainer) -> Optional[float]:\n",
    "    \"\"\"Compute RMSE on the trainer's val mask (None if not available).\"\"\"\n",
    "    if trainer.val_mask is None:\n",
    "        return None\n",
    "    mask = trainer.val_mask.detach().cpu().numpy().astype(bool)\n",
    "    if mask.sum() == 0:\n",
    "        return None\n",
    "    with torch.no_grad():\n",
    "        pred = trainer.model(trainer.x, trainer.edge_index,\n",
    "                             edge_weight=trainer.edge_weight,\n",
    "                             edge_attr=trainer.edge_attr).squeeze(1).detach().cpu().numpy()\n",
    "    y_true = trainer.y.squeeze(1).detach().cpu().numpy()[mask]\n",
    "    y_pred = pred[mask]\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "def _load_total_predictions(preds_path: str) -> Dict[str, float]:\n",
    "    df = pd.read_csv(preds_path, sep=\"\\t\")\n",
    "    return dict(zip(df[\"gene\"].astype(str), df[\"pred_beta\"].astype(float)))\n",
    "\n",
    "def _write_submodule_from_total(\n",
    "    graphml_path: str,\n",
    "    submodule: int,\n",
    "    total_pred_map: Dict[str, float],\n",
    "    outdir: str,\n",
    "    filename_tag: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Fallback writer: slice the submodule and fill pred_beta from total preds.\"\"\"\n",
    "    data, idx2gene, gene2idx = build_data_from_graphml(\n",
    "        graphml_path,\n",
    "        submodule=submodule,\n",
    "        add_degree_features=ADD_DEGREE_FEATURES,\n",
    "        use_label_as_feat=USE_LABEL_AS_FEAT,\n",
    "        add_community_feature=False,\n",
    "    )\n",
    "    genes = [idx2gene[i] for i in range(len(idx2gene))]\n",
    "    pred_beta = [total_pred_map.get(g, np.nan) for g in genes]\n",
    "    true_map = {}\n",
    "    y_np = data.y.squeeze(1).cpu().numpy()\n",
    "    has = data.has_label.cpu().numpy()\n",
    "    for i, ok in enumerate(has):\n",
    "        if ok:\n",
    "            true_map[idx2gene[i]] = float(y_np[i])\n",
    "    df = pd.DataFrame({\n",
    "        \"gene\": genes,\n",
    "        \"pred_beta\": pred_beta,\n",
    "        \"is_labeled\": has.astype(bool),\n",
    "        \"true_beta\": [true_map.get(g, np.nan) for g in genes],\n",
    "    })\n",
    "    out_path = os.path.join(outdir, f\"{filename_tag}_sub{submodule}_beta_predictions.tsv\")\n",
    "    df.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    return df\n",
    "\n",
    "def train_all_submodules(\n",
    "    graphml_path: str,\n",
    "    outdir: str,\n",
    "    submodules: Optional[List[int]] = None,\n",
    "    model_type: str = MODEL_TYPE,\n",
    "):\n",
    "    import torch  # local import to avoid hard dep in text context\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    set_seed(SEED)\n",
    "\n",
    "    # 1) Train total model once (for fallback use)\n",
    "    print(\"== Training TOTAL causal module ==\")\n",
    "    total_trainer, total_df = train_from_graphml(\n",
    "        graphml_path=graphml_path,\n",
    "        outdir=outdir,\n",
    "        submodule=None,\n",
    "        model_type=model_type,\n",
    "        seed=SEED,\n",
    "        hidden=HIDDEN,\n",
    "        layers=LAYERS,\n",
    "        heads=HEADS,\n",
    "        dropout=DROPOUT,\n",
    "        attn_dropout=ATTN_DROPOUT,\n",
    "        lr=LR,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        epochs=EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        val_size=VAL_SIZE,\n",
    "        add_degree_features=ADD_DEGREE_FEATURES,\n",
    "        use_label_as_feat=USE_LABEL_AS_FEAT,\n",
    "        add_community_feature=False,\n",
    "    )\n",
    "    total_pred_path = os.path.join(outdir, f\"{model_type}_suball_beta_predictions.tsv\")\n",
    "    total_df.to_csv(total_pred_path, sep=\"\\t\", index=False)\n",
    "    total_pred_map = _load_total_predictions(total_pred_path)\n",
    "\n",
    "    # 2) Determine submodule ids\n",
    "    if submodules is None:\n",
    "        submodules = list_submodules(graphml_path)\n",
    "    print(f\"Submodules to run: {submodules}\")\n",
    "\n",
    "    summary_rows = []\n",
    "    filename_tag = f\"{model_type}\"\n",
    "\n",
    "    # 3) Train each submodule (or fallback)\n",
    "    for m in submodules:\n",
    "        print(f\"\\n== Submodule {m} ==\")\n",
    "        try:\n",
    "            # Try to build data and ensure at least 2 labeled nodes to split\n",
    "            data, idx2gene, gene2idx = build_data_from_graphml(\n",
    "                graphml_path,\n",
    "                submodule=m,\n",
    "                add_degree_features=ADD_DEGREE_FEATURES,\n",
    "                use_label_as_feat=USE_LABEL_AS_FEAT,\n",
    "                add_community_feature=False,\n",
    "            )\n",
    "            n_nodes = data.x.shape[0]\n",
    "            n_edges = int(data.edge_index.shape[1] // 2)  # approx undirected no self-loops\n",
    "            n_labeled = int(data.has_label.sum().item())\n",
    "            print(f\"Nodes={n_nodes}  Labeled={n_labeled}\")\n",
    "\n",
    "            if n_labeled < 2:\n",
    "                print(\"  Not enough labeled nodes; using TOTAL-model fallback.\")\n",
    "                df = _write_submodule_from_total(\n",
    "                    graphml_path, m, total_pred_map, outdir, filename_tag\n",
    "                )\n",
    "                trained = False\n",
    "                val_rmse = np.nan\n",
    "            else:\n",
    "                in_dim = data.x.shape[1]\n",
    "                hps = dict(hidden=HIDDEN, layers=LAYERS, dropout=DROPOUT, heads=HEADS, attn_dropout=ATTN_DROPOUT)\n",
    "                model = build_model(model_type, in_dim, hps)\n",
    "                trainer = Trainer(data, model, lr=LR, weight_decay=WEIGHT_DECAY, patience=PATIENCE)\n",
    "                trainer.split_masks(val_size=VAL_SIZE, seed=SEED)\n",
    "                trainer.train(epochs=EPOCHS, verbose=True)\n",
    "                val_rmse = _compute_val_rmse(trainer)\n",
    "\n",
    "                out_path = os.path.join(outdir, f\"{filename_tag}_sub{m}_beta_predictions.tsv\")\n",
    "                df = trainer.export_predictions(out_path)\n",
    "                trained = True\n",
    "\n",
    "            summary_rows.append({\n",
    "                \"submodule\": m,\n",
    "                \"n_nodes\": n_nodes,\n",
    "                \"n_labeled\": n_labeled,\n",
    "                \"trained\": trained,\n",
    "                \"val_rmse\": val_rmse,\n",
    "                \"out_path\": os.path.join(outdir, f\"{filename_tag}_sub{m}_beta_predictions.tsv\"),\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR on submodule {m}: {e}\")\n",
    "            # As last resort, try to still write fallback\n",
    "            try:\n",
    "                df = _write_submodule_from_total(\n",
    "                    graphml_path, m, total_pred_map, outdir, filename_tag\n",
    "                )\n",
    "                summary_rows.append({\n",
    "                    \"submodule\": m,\n",
    "                    \"n_nodes\": len(df),\n",
    "                    \"n_labeled\": int(df[\"is_labeled\"].sum()),\n",
    "                    \"trained\": False,\n",
    "                    \"val_rmse\": np.nan,\n",
    "                    \"out_path\": os.path.join(outdir, f\"{filename_tag}_sub{m}_beta_predictions.tsv\"),\n",
    "                })\n",
    "            except Exception as e2:\n",
    "                print(f\"  Fallback failed for submodule {m}: {e2}\")\n",
    "\n",
    "    # 4) Save summary\n",
    "    summary_df = pd.DataFrame(summary_rows).sort_values(\"submodule\")\n",
    "    summary_path = os.path.join(outdir, f\"{MODEL_TYPE}_submodules_summary.csv\")\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(\"\\nWrote summary to:\", summary_path)\n",
    "    return summary_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    summary = train_all_submodules(GRAPHML, OUTDIR, submodules=list(range(0, 13)), model_type=MODEL_TYPE)\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eeab38",
   "metadata": {},
   "source": [
    "**Step 4:** Community detection / resolution sweep on the PPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c680b40a-1460-4d30-a943-e9efbc8e01d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading expression matrix...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === Load expression matrix ===\n",
    "print(\"Loading expression matrix...\")\n",
    "\n",
    "with open(\"/mnt/f/10_osteo_MR/datasets/gse123568/gene_expr_and_labels.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "gene_expr_norm = data[\"gene_expr_norm\"]\n",
    "group_label = data[\"group_labels\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133cece8",
   "metadata": {},
   "source": [
    "**Step 6:** Load network or tabular inputs (PPI/GraphML/TSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91a2895c-6378-41b6-b1e9-1729d89470a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote per-sample partial ci-PTRS: /mnt/f/10_osteo_MR/result_drug_target/module_sig_drug/ci_ptrs_partial_top10/partial_ci_ptrs_top10_GAT.tsv\n",
      "Wrote group summary: /mnt/f/10_osteo_MR/result_drug_target/module_sig_drug/ci_ptrs_partial_top10/partial_ci_ptrs_top10_GAT_by_group.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# -----------------------\n",
    "# USER CONFIG\n",
    "# -----------------------\n",
    "GRAPHML = \"/mnt/f/10_osteo_MR/results_network/largest_causal_subnet_A2_a6_g0.001832981/causal_modules.graphml\"\n",
    "SUB_BETA_DIR = \"/mnt/f/10_osteo_MR/gnn_from_graphml_runs_submodules\"  # where GAT_sub<m>_beta_predictions.tsv live\n",
    "MODEL_TAG = \"GAT\"                         # change if you trained with another tag\n",
    "DRUGMAP = \"/mnt/f/10_osteo_MR/result_drug_target/drugmap_drug_gene_by_moa_status.csv\"\n",
    "OUT_BASE = \"/mnt/f/10_osteo_MR/result_drug_target/module_sig_drug/ci_ptrs_partial_top10\"\n",
    "os.makedirs(OUT_BASE, exist_ok=True)\n",
    "\n",
    "# Your top-10 drug IDs and their submodules (order per table provided)\n",
    "TOP10_IDS = ['DMDYC4J','DM21WBH','DMCVJK9','DMF3DZX','DMN9YOB','DM38N2K','DM42PFT','DMBZMYT','DMBPNKT','DMH5RFU']\n",
    "\n",
    "TOP10_SUBMODULES = [0, 0, 0, 2, 2, 5, 0, 0, 5, 0]  # from your table rows (in the same order)\n",
    "\n",
    "TOP10_IDS = ['DMDYC4J',\n",
    "'DMCVJK9',\n",
    "'DM21WBH',\n",
    "'DM42PFT',\n",
    "'DMF3DZX',\n",
    "'DMSFWT7',\n",
    "'DMH5RFU',\n",
    "'DMN9YOB',\n",
    "'DMBZMYT',\n",
    "'DM5DMCH']\n",
    "\n",
    "TOP10_SUBMODULES = [6,\n",
    "6,\n",
    "6,\n",
    "6,\n",
    "0,\n",
    "6,\n",
    "6,\n",
    "0,\n",
    "6,\n",
    "6]\n",
    "\n",
    "\n",
    "\n",
    "DECAY_PER_HOP = 0.5       # weight = (DECAY_PER_HOP ** distance), distance in {0,1,2}\n",
    "MAX_HOPS = 1          # include 0,1,2-hop\n",
    "\n",
    "# IMPORTANT:\n",
    "# Expect gene_expr_norm (DataFrame: genes x samples) and group_label (list[str]) to be already in memory.\n",
    "# If you want to load from file, replace these with your loader.\n",
    "# Example placeholders below (comment out if already in memory):\n",
    "# gene_expr_norm = pd.read_parquet(\"/path/to/gene_expr_norm.parquet\")  # genes x samples\n",
    "# group_label = pd.read_csv(\"/path/to/group_labels.csv\")[\"group\"].tolist()\n",
    "\n",
    "# -----------------------\n",
    "# HELPERS\n",
    "# -----------------------\n",
    "def load_submodule_graph(graphml_path: str, submodule: int, community_attr: str = \"community\") -> nx.Graph:\n",
    "    G = nx.read_graphml(graphml_path)\n",
    "    keep = [n for n, d in G.nodes(data=True) if int(d.get(community_attr, -1)) == int(submodule)]\n",
    "    return G.subgraph(keep).copy()\n",
    "\n",
    "def load_submodule_betas(sub_beta_dir: str, model_tag: str, submodule: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns pd.Series beta_hat indexed by gene (str).\n",
    "    Reads: {dir}/{MODEL_TAG}_sub{submodule}_beta_predictions.tsv\n",
    "    \"\"\"\n",
    "    p = os.path.join(sub_beta_dir, f\"{model_tag}_sub{submodule}_beta_predictions.tsv\")\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"Missing beta predictions for submodule {submodule}: {p}\")\n",
    "    df = pd.read_csv(p, sep=\"\\t\")\n",
    "    if not {\"gene\",\"pred_beta\"}.issubset(df.columns):\n",
    "        raise ValueError(f\"Missing columns in {p}\")\n",
    "    return pd.Series(df[\"pred_beta\"].values, index=df[\"gene\"].astype(str))\n",
    "\n",
    "def load_drug_targets(drugmap_csv: str, drug_ids: list) -> dict:\n",
    "    \"\"\"\n",
    "    Returns {DrugID: set(genes)} for requested IDs, filtered to Gene_clean not null.\n",
    "    \"\"\"\n",
    "    dm = pd.read_csv(drugmap_csv)\n",
    "    dm = dm.dropna(subset=[\"DrugID\",\"Gene_clean\"])\n",
    "    dm[\"DrugID\"] = dm[\"DrugID\"].astype(str)\n",
    "    dm[\"Gene_clean\"] = dm[\"Gene_clean\"].astype(str)\n",
    "    targets = defaultdict(set)\n",
    "    for did, g in zip(dm[\"DrugID\"], dm[\"Gene_clean\"]):\n",
    "        if did in drug_ids:\n",
    "            targets[did].add(g)\n",
    "    return dict(targets)\n",
    "\n",
    "def k_hop_weights(Gm: nx.Graph, seeds: set, max_hops: int = 2, decay: float = 0.5) -> dict:\n",
    "    \"\"\"\n",
    "    Compute per-node distance from seed set within Gm (unweighted graph distance),\n",
    "    then weight = decay ** dist for dist in [0..max_hops]. For nodes farther than max_hops, weight=0.\n",
    "    If multiple seeds reach a node, we take the MAX weight (i.e., min distance).\n",
    "    \"\"\"\n",
    "    if not seeds:\n",
    "        return {}\n",
    "    # Multi-source BFS\n",
    "    dist = {n: np.inf for n in Gm.nodes()}\n",
    "    q = deque()\n",
    "    for s in seeds:\n",
    "        if s in Gm:\n",
    "            dist[s] = 0\n",
    "            q.append(s)\n",
    "    while q:\n",
    "        u = q.popleft()\n",
    "        if dist[u] >= max_hops:  # we don't need beyond max_hops\n",
    "            continue\n",
    "        for v in Gm.neighbors(u):\n",
    "            if dist[v] > dist[u] + 1:\n",
    "                dist[v] = dist[u] + 1\n",
    "                if dist[v] <= max_hops:\n",
    "                    q.append(v)\n",
    "    weights = {}\n",
    "    for n, d in dist.items():\n",
    "        if d == np.inf or d > max_hops:\n",
    "            continue\n",
    "        weights[n] = (decay ** d)\n",
    "    return weights\n",
    "\n",
    "def compute_partial_ci_ptrs_for_drug(\n",
    "    drug_id: str,\n",
    "    submodule: int,\n",
    "    G_full_path: str,\n",
    "    sub_beta_dir: str,\n",
    "    model_tag: str,\n",
    "    drug_targets_map: dict,\n",
    "    gene_expr_norm: pd.DataFrame,\n",
    "    decay: float = 0.5,\n",
    "    max_hops: int = 2,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns per-sample ci-PTRS (Series indexed by sample) for this drug/submodule.\n",
    "    \"\"\"\n",
    "    # Subgraph and betas\n",
    "    Gm = load_submodule_graph(G_full_path, submodule)\n",
    "    beta_hat = load_submodule_betas(sub_beta_dir, model_tag, submodule)\n",
    "\n",
    "    # Targets inside this submodule\n",
    "    seeds = set(t for t in drug_targets_map.get(drug_id, set()) if t in Gm)\n",
    "    if not seeds:\n",
    "        # No nodes -> zero score for all samples (but keep output)\n",
    "        return pd.Series(0.0, index=gene_expr_norm.columns, name=drug_id)\n",
    "\n",
    "    # Neighborhood weights\n",
    "    w = k_hop_weights(Gm, seeds, max_hops=max_hops, decay=decay)\n",
    "    if not w:\n",
    "        # Only isolated seeds (0-hop only if in Gm)\n",
    "        w = {s: 1.0 for s in seeds if s in Gm}\n",
    "\n",
    "    # Build aligned vectors over contributing genes\n",
    "    genes = [g for g in w.keys() if g in beta_hat.index and g in gene_expr_norm.index]\n",
    "    if not genes:\n",
    "        return pd.Series(0.0, index=gene_expr_norm.columns, name=drug_id)\n",
    "\n",
    "    b = beta_hat.loc[genes].values            # (n_genes,)\n",
    "    a = np.array([w[g] for g in genes])       # (n_genes,)\n",
    "    # Expression matrix slice: genes x samples\n",
    "    X = gene_expr_norm.loc[genes].values      # (n_genes, n_samples)\n",
    "\n",
    "    # ci-PTRS per sample = sum_i (b_i * a_i * x_{i,s})\n",
    "    scores = (b[:, None] * a[:, None] * X).sum(axis=0)\n",
    "    return pd.Series(scores, index=gene_expr_norm.columns, name=drug_id)\n",
    "\n",
    "# -----------------------\n",
    "# MAIN\n",
    "# -----------------------\n",
    "def main():\n",
    "    # 1) Map drug -> submodule\n",
    "    drug_to_m = {did: TOP10_SUBMODULES[i] for i, did in enumerate(TOP10_IDS)}\n",
    "\n",
    "    # 2) Load DrugMap targets for these drugs\n",
    "    drug_targets = load_drug_targets(DRUGMAP, TOP10_IDS)\n",
    "\n",
    "    # 3) Compute per-drug per-sample ci-PTRS\n",
    "    all_scores = []\n",
    "    for did in TOP10_IDS:\n",
    "        m = drug_to_m[did]\n",
    "        s = compute_partial_ci_ptrs_for_drug(\n",
    "            drug_id=did,\n",
    "            submodule=m,\n",
    "            G_full_path=GRAPHML,\n",
    "            sub_beta_dir=SUB_BETA_DIR,\n",
    "            model_tag=MODEL_TAG,\n",
    "            drug_targets_map=drug_targets,\n",
    "            gene_expr_norm=gene_expr_norm,    # must be defined in your session\n",
    "            decay=DECAY_PER_HOP,\n",
    "            max_hops=MAX_HOPS,\n",
    "        )\n",
    "        all_scores.append(s)\n",
    "\n",
    "    scores_df = pd.concat(all_scores, axis=1)   # samples x drugs (columns=DrugID)\n",
    "    scores_out = os.path.join(OUT_BASE, f\"partial_ci_ptrs_top10_{MODEL_TAG}.tsv\")\n",
    "    scores_df.to_csv(scores_out, sep=\"\\t\")\n",
    "    print(\"Wrote per-sample partial ci-PTRS:\", scores_out)\n",
    "\n",
    "    # 4) Add simple group summary if group_label is available\n",
    "    try:\n",
    "        groups = pd.Series(group_label, index=scores_df.index, name=\"group\")\n",
    "        summary = (scores_df.assign(group=groups)\n",
    "                   .groupby(\"group\").agg([\"mean\",\"std\",\"count\"]))\n",
    "        summ_out = os.path.join(OUT_BASE, f\"partial_ci_ptrs_top10_{MODEL_TAG}_by_group.tsv\")\n",
    "        summary.to_csv(summ_out, sep=\"\\t\")\n",
    "        print(\"Wrote group summary:\", summ_out)\n",
    "    except Exception as e:\n",
    "        print(\"Group summary skipped (need group_label aligned to columns):\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44fbcf",
   "metadata": {},
   "source": [
    "**Step 7:** Load network or tabular inputs (PPI/GraphML/TSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2428e78-b9b2-412d-9886-51a243d2df37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 10)\n",
      "Saved: /mnt/f/10_osteo_MR/result_drug_target/module_sig_drug/ci_ptrs_partial_top10/partial_ci_ptrs_top10_heatmap_no_clust.pdf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_heatmaps(scores_df, outdir, tag=\"partial_ci_ptrs_top10\"):\n",
    "\n",
    "    print( scores_df.shape )\n",
    "    vals = scores_df.values.flatten()\n",
    "    vmin, vmax = np.percentile(vals, [5, 95])\n",
    "    # sns.heatmap(scores_df.T, cmap=\"RdBu_r\", center=0, vmin=vmin, vmax=vmax)\n",
    "    vmin, vmx = -1, 1\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(scores_df.T, cmap=\"RdBu_r\", center=0, cbar_kws={'label': 'PTRS'}, \n",
    "                linewidth=1, vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"Partial ci-PTRS Heatmap (no clustering)\")\n",
    "    plt.ylabel(\"Drug ID\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.tight_layout()\n",
    "    path1 = os.path.join(outdir, f\"{tag}_heatmap_no_clust.pdf\")\n",
    "    plt.savefig(path1, dpi=200)\n",
    "    plt.close()\n",
    "    print(\"Saved:\", path1)\n",
    "\n",
    "   \n",
    "scores_out = os.path.join(OUT_BASE, f\"partial_ci_ptrs_top10_{MODEL_TAG}.tsv\")\n",
    "scores_df = pd.read_csv(scores_out, sep=\"\\t\" , index_col = 0 )\n",
    "\n",
    "plot_heatmaps( scores_df, OUT_BASE )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
