{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2225ff9",
   "metadata": {},
   "source": [
    "# 01 GWAS-TWAS preprocessing\n",
    "\n",
    "**Origin:** `0_1_preprocessing_gwas_twas.ipynb`  \n",
    "**This annotated version was generated on:** 2025-10-13 06:41\n",
    "\n",
    "**What this notebook does (high level):**  \n",
    "- Preprocess GWAS/TWAS summary statistics: harmonization, allele alignment, liftover checks, and basic QC.\n",
    "\n",
    "**How to use:**  \n",
    "1. Review the markdown notes before each code cell.  \n",
    "2. Adjust input/output paths as needed for your environment.  \n",
    "3. Run cell-by-cell to reproduce artifacts for downstream steps.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbbcaf6",
   "metadata": {},
   "source": [
    "**Step 1:** Filesystem setup and path management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6860b828-58a9-493f-88f4-bcd03ff97cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import os, re, gzip\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c04e9b",
   "metadata": {},
   "source": [
    "**Step 2:** Load tabular data (summary stats / annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de44a04-54a3-426c-bc00-681087485c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outcome 1: OSTEONECROSIS\n",
    "osteo1 = pd.read_csv(\"/mnt/f/10_osteo_MR/datasets/outcome/summary_stats_release_finngen_R12_M13_OSTEONECROSIS.gz\", sep=\"\\t\")\n",
    "osteo1_out = osteo1.rename(columns={\n",
    "    'rsids': 'SNP',\n",
    "    'beta': 'beta',\n",
    "    'sebeta': 'se',\n",
    "    'ref': 'other_allele',\n",
    "    'alt': 'effect_allele',\n",
    "    'pval': 'pval'\n",
    "})[['SNP', 'beta', 'se', 'effect_allele', 'other_allele', 'pval']]\n",
    "# osteo1_out.to_csv(\"/mnt/f/10_osteo_MR/MR_ready/outcome_osteo_whole_snp.tsv\", sep='\\t', index=False)\n",
    "\n",
    "\n",
    "# Outcome 2: OSTEO_DRUGS\n",
    "osteo2 = pd.read_csv(\"/mnt/f/10_osteo_MR/datasets/outcome/summary_stats_release_finngen_R12_OSTEON_DRUGS.gz\", sep=\"\\t\")\n",
    "osteo2_out = osteo2.rename(columns={\n",
    "    'rsids': 'SNP',\n",
    "    'beta': 'beta',\n",
    "    'sebeta': 'se',\n",
    "    'ref': 'other_allele',\n",
    "    'alt': 'effect_allele',\n",
    "    'pval': 'pval'\n",
    "})[['SNP', 'beta', 'se', 'effect_allele', 'other_allele', 'pval']]\n",
    "# osteo2_out.to_csv(\"/mnt/f/10_osteo_MR/MR_ready/outcome_osteo_drugs.tsv\", sep='\\t', index=False)\n",
    "\n",
    "\n",
    "outcome_rsid = set( pd.read_csv( \"/mnt/f/10_osteo_MR/MR_ready/outcome_osteo_whole_snp.tsv\", sep='\\t', usecols=['SNP'], dtype=str )['SNP'].to_list() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c53c1ca",
   "metadata": {},
   "source": [
    "**Step 3:** Load tabular data (summary stats / annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e5c7964-5547-4bc7-bf35-b0bd2b1b2111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] RSIDs-in-DHS: 32,364,424  | with DHS id: 32,364,424\n",
      "[done] Wrote 597,125 GWAS rows with dhs_id → /mnt/f/10_osteo_MR/datasets/dhs_context/summary_stats_release_finngen_R12_M13_OSTEONECROSIS.within_wb_DHS.tsv.gz\n",
      "[note] Total GWAS rows scanned: 21,326,767\n",
      "[done] MR-ready outcome with dhs_id → /mnt/f/10_osteo_MR/MR_ready/outcome_osteo_within_wb_DHS.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Write GWAS subset WITH dhs_id (RSID join only; NA-safe; Lymphoid precedence)\n",
    "\n",
    "import os, re, gzip\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Inputs ---\n",
    "gwas_path = \"/mnt/f/10_osteo_MR/datasets/outcome/summary_stats_release_finngen_R12_M13_OSTEONECROSIS.gz\"\n",
    "# Merged RSID↔DHS table (columns: CHROM, POS, rsid, component, lym_id, mye_id)\n",
    "merged_map_path = \"/mnt/f/0.datasets/ens_vcf_dhs/rsid_in_DHS_merged_lym_mye.tsv.gz\"\n",
    "\n",
    "# --- Outputs ---\n",
    "out_dir  = \"/mnt/f/10_osteo_MR/datasets/dhs_context\"\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "gwas_out = os.path.join(out_dir, \"summary_stats_release_finngen_R12_M13_OSTEONECROSIS.within_wb_DHS.tsv.gz\")\n",
    "\n",
    "# 1) Build RSID→DHS-ID map (prefer lym_id, else mye_id)\n",
    "m = pd.read_csv(\n",
    "    merged_map_path, sep=\"\\t\", compression=\"infer\",\n",
    "    usecols=[\"rsid\",\"lym_id\",\"mye_id\"],\n",
    "    dtype={\"rsid\":\"string\",\"lym_id\":\"string\",\"mye_id\":\"string\"}\n",
    ").dropna(subset=[\"rsid\"])\n",
    "m[\"dhs_id\"] = m[\"lym_id\"].where(m[\"lym_id\"].notna() & (m[\"lym_id\"] != \"\"), m[\"mye_id\"])\n",
    "rsid2dhs = dict(zip(m[\"rsid\"].astype(str), m[\"dhs_id\"].astype(\"string\").fillna(\"\").astype(str)))\n",
    "\n",
    "# Also keep the RSID set for quick membership filtering\n",
    "rsids_in_dhs = set(rsid2dhs.keys())\n",
    "print(f\"[info] RSIDs-in-DHS: {len(rsids_in_dhs):,}  | with DHS id: {sum(bool(v) for v in rsid2dhs.values()):,}\")\n",
    "\n",
    "# 2) Helpers\n",
    "splitter = re.compile(r\"[;,\\s]+\")\n",
    "\n",
    "def any_in_dhs(rs_field: str) -> bool:\n",
    "    if rs_field is None or pd.isna(rs_field): return False\n",
    "    s = str(rs_field)\n",
    "    if not s or s == \".\": return False\n",
    "    for tok in splitter.split(s):\n",
    "        if tok and tok in rsids_in_dhs:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def first_dhs_id(rs_field: str) -> str:\n",
    "    \"\"\"Return the FIRST DHS id found among the rsids in this row (lym precedence already baked into map).\"\"\"\n",
    "    if rs_field is None or pd.isna(rs_field): return \"\"\n",
    "    s = str(rs_field)\n",
    "    if not s or s == \".\": return \"\"\n",
    "    for tok in splitter.split(s):\n",
    "        if tok and tok in rsid2dhs:\n",
    "            did = rsid2dhs.get(tok, \"\")\n",
    "            if did and did != \"nan\":\n",
    "                return did\n",
    "    return \"\"\n",
    "\n",
    "# 3) Stream GWAS, keep only rows with RSID in DHS, and append dhs_id\n",
    "written = total = 0\n",
    "first = True\n",
    "chunksize = 1_000_000\n",
    "\n",
    "with gzip.open(gwas_out, \"wt\") as gzout:\n",
    "    for chunk in pd.read_csv(gwas_path, sep=\"\\t\", compression=\"infer\", dtype=\"string\", chunksize=chunksize):\n",
    "        total += len(chunk)\n",
    "        if \"rsids\" not in chunk.columns:\n",
    "            raise ValueError(\"Input GWAS file is missing the 'rsids' column.\")\n",
    "        rs = chunk[\"rsids\"].astype(\"string\").fillna(\"\")\n",
    "        mask = rs.map(any_in_dhs)\n",
    "        sub  = chunk.loc[mask].copy()\n",
    "        if not sub.empty:\n",
    "            # add dhs_id column (first matching RSID’s DHS ID)\n",
    "            sub[\"dhs_id\"] = rs.loc[sub.index].map(first_dhs_id).astype(str)\n",
    "            sub.to_csv(gzout, sep=\"\\t\", index=False, header=first)\n",
    "            written += len(sub)\n",
    "            first = False\n",
    "\n",
    "print(f\"[done] Wrote {written:,} GWAS rows with dhs_id → {gwas_out}\")\n",
    "print(f\"[note] Total GWAS rows scanned: {total:,}\")\n",
    "\n",
    "# 4) Build MR-ready outcome file (carry dhs_id through)\n",
    "osteo1 = pd.read_csv(gwas_out, sep=\"\\t\", compression=\"infer\", dtype=\"string\")\n",
    "\n",
    "# Rename and select columns for MR tool; keep dhs_id\n",
    "# Finngen headers => MR: SNP, beta, se, effect_allele, other_allele, pval\n",
    "osteo1_out = osteo1.rename(columns={\n",
    "    \"rsids\": \"SNP\",\n",
    "    \"beta\": \"beta\",\n",
    "    \"sebeta\": \"se\",\n",
    "    \"alt\": \"effect_allele\",\n",
    "    \"ref\": \"other_allele\",\n",
    "    \"pval\": \"pval\",\n",
    "})[[\"SNP\",\"beta\",\"se\",\"effect_allele\",\"other_allele\",\"pval\",\"dhs_id\"]]\n",
    "\n",
    "mr_out = \"/mnt/f/10_osteo_MR/MR_ready/outcome_osteo_within_wb_DHS.tsv\"\n",
    "osteo1_out.to_csv(mr_out, sep=\"\\t\", index=False)\n",
    "print(f\"[done] MR-ready outcome with dhs_id → {mr_out}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d121c",
   "metadata": {},
   "source": [
    "**Step 4:** Join/merge datasets to align keys across resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c41c65-06c2-46cd-b6ca-2d6559997007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Output written to: /mnt/f/10_osteo_MR/datasets/expo/2019-12-11-cis-eQTLsFDR0.05-ProbeLevel-CohortInfoRemoved-BonferroniAdded_eqtls_beta_se.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# eqtlgen \n",
    "# \n",
    "# Step 2: Prepare input/output files\n",
    "infile = \"/mnt/e/0.datasets/eqtlGen/2019-12-11-cis-eQTLsFDR0.05-ProbeLevel-CohortInfoRemoved-BonferroniAdded.txt.gz\"\n",
    "outfile = \"/mnt/f/10_osteo_MR/datasets/expo/2019-12-11-cis-eQTLsFDR0.05-ProbeLevel-CohortInfoRemoved-BonferroniAdded_eqtls_beta_se.tsv\"\n",
    "N = 31864  # max sample size as per instruction\n",
    "alleleFreq = 0.5  # Set to 0.5 if unknown (this is the most conservative assumption)\n",
    "\n",
    "with gzip.open(infile, 'rt') as fin, open(outfile, 'w') as fout:\n",
    "    header = fin.readline().strip().split('\\t')\n",
    "    # Write new header\n",
    "    fout.write('\\t'.join(header + [\"beta\", \"se\"]) + '\\n')\n",
    "    \n",
    "    for line in fin:\n",
    "        fields = line.strip().split('\\t')\n",
    "        if len(fields) < 14:\n",
    "            continue\n",
    "        try:\n",
    "            z = float(fields[6])\n",
    "        except Exception:\n",
    "            continue\n",
    "        # Compute beta and se\n",
    "        denom = math.sqrt(2 * alleleFreq * (1 - alleleFreq) * (N + z ** 2))\n",
    "        beta = z / denom\n",
    "        se = 1 / denom\n",
    "        # Write row with computed values\n",
    "        fout.write('\\t'.join(fields + [f\"{beta:.6g}\", f\"{se:.6g}\"]) + '\\n')\n",
    "\n",
    "print(f\"Done. Output written to: {outfile}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d583d89",
   "metadata": {},
   "source": [
    "**Step 5:** Load tabular data (summary stats / annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "273fe6c7-b937-48a9-beb4-bc3491efcf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] RSIDs in DHS (from outcome): 606,769\n",
      "[chunk 0] matches: 48,057 | running groups: 38,706\n",
      "[chunk 1] matches: 45,845 | running groups: 75,333\n",
      "[chunk 2] matches: 45,104 | running groups: 111,135\n",
      "[chunk 3] matches: 43,743 | running groups: 145,704\n",
      "[chunk 4] matches: 43,089 | running groups: 179,435\n",
      "[chunk 5] matches: 43,546 | running groups: 213,411\n",
      "[chunk 6] matches: 42,600 | running groups: 246,624\n",
      "[chunk 7] matches: 42,973 | running groups: 280,179\n",
      "[chunk 8] matches: 42,647 | running groups: 313,258\n",
      "[chunk 9] matches: 42,662 | running groups: 346,324\n",
      "[chunk 10] matches: 21,795 | running groups: 363,123\n",
      "[done] total groups (GeneSymbol, dhs_id): 363,123\n",
      "[saved] /mnt/f/10_osteo_MR/MR_ready/exposure_eqtlgen_dhs_index.tsv  (rows: 363,123)\n"
     ]
    }
   ],
   "source": [
    "# %% One-SNP-per-DHS-per-gene from eQTLGen (using DHS RSIDs from outcome file)\n",
    "import os, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Inputs ----\n",
    "eqtlgen_file = \"/mnt/f/10_osteo_MR/datasets/expo/2019-12-11-cis-eQTLsFDR0.05-ProbeLevel-CohortInfoRemoved-BonferroniAdded_eqtls_beta_se.tsv\"\n",
    "outcome_with_dhs = \"/mnt/f/10_osteo_MR/MR_ready/outcome_osteo_within_wb_DHS.tsv\"   # has columns SNP (possibly 'rs1;rs2;...') and dhs_id\n",
    "\n",
    "# ---- Output ----\n",
    "final_out = \"/mnt/f/10_osteo_MR/MR_ready/exposure_eqtlgen_dhs_index.tsv\"\n",
    "Path(os.path.dirname(final_out)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- 1) Build RSID -> dhs_id map from outcome file (split multi-rsid) ----\n",
    "splitter = re.compile(r\"[;,\\s]+\")\n",
    "snp2dhs = {}\n",
    "\n",
    "out_df = pd.read_csv(outcome_with_dhs, sep=\"\\t\", dtype=\"string\", usecols=[\"SNP\",\"dhs_id\"])\n",
    "for s, did in zip(out_df[\"SNP\"], out_df[\"dhs_id\"]):\n",
    "    if pd.isna(s):\n",
    "        continue\n",
    "    did_str = \"\" if pd.isna(did) else str(did)\n",
    "    for tok in splitter.split(str(s)):\n",
    "        if tok and tok != \".\":\n",
    "            # keep the first mapping we see; outcome file already applies lymphoid precedence\n",
    "            if tok not in snp2dhs:\n",
    "                snp2dhs[tok] = did_str\n",
    "\n",
    "dhs_rsids = set(snp2dhs.keys())\n",
    "print(f\"[info] RSIDs in DHS (from outcome): {len(dhs_rsids):,}\")\n",
    "\n",
    "# ---- 2) Stream eQTLGen and keep only SNPs in DHS set; reduce to best per (GeneSymbol, dhs_id) ----\n",
    "# We'll keep a compact 'best' table and update it chunk-by-chunk\n",
    "best_df = pd.DataFrame(columns=[\n",
    "    \"SNP\",\"beta\",\"se\",\"AssessedAllele\",\"OtherAllele\",\"GeneSymbol\",\"Pvalue\",\"Zscore\",\"dhs_id\"\n",
    "])\n",
    "\n",
    "def reduce_to_best(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return one row per (GeneSymbol, dhs_id):\n",
    "       lowest Pvalue, then highest |Zscore|, then first.\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    tmp = df.copy()\n",
    "    # numeric keys\n",
    "    tmp[\"pval_num\"] = pd.to_numeric(tmp[\"Pvalue\"], errors=\"coerce\")\n",
    "    tmp[\"abs_z\"]    = pd.to_numeric(tmp[\"Zscore\"], errors=\"coerce\").abs()\n",
    "    tmp[\"abs_z\"]    = tmp[\"abs_z\"].fillna(-np.inf)\n",
    "    # sort and keep first per group\n",
    "    tmp = tmp.sort_values([\"GeneSymbol\",\"dhs_id\",\"pval_num\",\"abs_z\"],\n",
    "                          ascending=[True, True, True, False])\n",
    "    return tmp.groupby([\"GeneSymbol\",\"dhs_id\"], as_index=False).head(1)\n",
    "\n",
    "chunksize = 1_000_000\n",
    "required_cols = [\"Pvalue\",\"SNP\",\"AssessedAllele\",\"OtherAllele\",\"Zscore\",\"GeneSymbol\",\"beta\",\"se\"]\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(eqtlgen_file, sep=\"\\t\", dtype=\"string\",\n",
    "                                      usecols=required_cols, chunksize=chunksize)):\n",
    "    # filter to SNPs present in the DHS RSID set\n",
    "    mask = chunk[\"SNP\"].isin(dhs_rsids)\n",
    "    sub = chunk.loc[mask].copy()\n",
    "    if sub.empty:\n",
    "        print(f\"[chunk {i}] matches: 0 (skipped)\")\n",
    "        continue\n",
    "\n",
    "    # attach dhs_id via RSID map\n",
    "    sub[\"dhs_id\"] = sub[\"SNP\"].map(snp2dhs).astype(\"string\")\n",
    "\n",
    "    # local reduction to one row per (GeneSymbol, dhs_id)\n",
    "    local_best = reduce_to_best(sub)\n",
    "\n",
    "    # merge with global best and reduce again\n",
    "    if best_df.empty:\n",
    "        best_df = local_best\n",
    "    else:\n",
    "        combined = pd.concat([best_df, local_best], ignore_index=True)\n",
    "        best_df = reduce_to_best(combined)\n",
    "\n",
    "    print(f\"[chunk {i}] matches: {len(sub):,} | running groups: {best_df.shape[0]:,}\")\n",
    "\n",
    "print(f\"[done] total groups (GeneSymbol, dhs_id): {best_df.shape[0]:,}\")\n",
    "\n",
    "# ---- 3) Build MR-ready exposure file (keep dhs_id for traceability) ----\n",
    "eqtlgen_exp = best_df.rename(columns={\n",
    "    \"AssessedAllele\": \"effect_allele\",\n",
    "    \"OtherAllele\": \"other_allele\",\n",
    "    \"GeneSymbol\": \"gene\",\n",
    "    \"Pvalue\": \"pval\"\n",
    "})[[\"SNP\",\"beta\",\"se\",\"effect_allele\",\"other_allele\",\"gene\",\"pval\",\"dhs_id\"]]\n",
    "\n",
    "eqtlgen_exp.to_csv(final_out, sep=\"\\t\", index=False)\n",
    "print(f\"[saved] {final_out}  (rows: {len(eqtlgen_exp):,})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d591f9",
   "metadata": {},
   "source": [
    "**Step 6:** Load tabular data (summary stats / annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "776ea0c3-fbaa-4e60-b8cc-ea12e3ee4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] DHS RSIDs from outcome: 606,769\n",
      "[info] GTEx WB rows (significant pairs): 2,985,690\n",
      "[info] Rows after DHS RSID filter: 158,211\n",
      "[info] Final (gene × DHS) picks: 110,483\n",
      "[done] MR exposure written → /mnt/f/10_osteo_MR/MR_ready/exposure_gtex_whole_blood_eqtl_dhs_index.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %% GTEx WB → MR exposure (within DHS; one SNP per gene×DHS by p-value, tie by |Z|)\n",
    "import os, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- Inputs ----------\n",
    "eqtl_path     = \"/mnt/f/0.datasets/gtex/gtex_v10_qtl_data/GTEx_Analysis_v10_eQTL_updated/Whole_Blood.v10.eQTLs.signif_pairs.parquet\"\n",
    "lookup_path   = \"/mnt/f/0.datasets/gtex/gtex_v10_qtl_data/GTEx_Analysis_2021-02-11_v10_WholeGenomeSeq_953Indiv.lookup_table.txt.gz\"\n",
    "gtf_path      = \"/mnt/f/0.datasets/gtex/gtex_v10_qtl_data/gencode.v39.GRCh38.genes.gtf\"\n",
    "outcome_with_dhs = \"/mnt/f/10_osteo_MR/MR_ready/outcome_osteo_within_wb_DHS.tsv\"  # columns: SNP (may be 'rs1;rs2;...'), dhs_id\n",
    "\n",
    "# ---------- Output ----------\n",
    "mr_out = \"/mnt/f/10_osteo_MR/MR_ready/exposure_gtex_whole_blood_eqtl_dhs_index.tsv\"\n",
    "Path(os.path.dirname(mr_out)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- 0) RSIDs within DHS (and dhs_id) from outcome file ----------\n",
    "splitter = re.compile(r\"[;,\\s]+\")\n",
    "snp2dhs = {}\n",
    "out_df = pd.read_csv(outcome_with_dhs, sep=\"\\t\", dtype=\"string\", usecols=[\"SNP\",\"dhs_id\"])\n",
    "for s, did in zip(out_df[\"SNP\"], out_df[\"dhs_id\"]):\n",
    "    if pd.isna(s):\n",
    "        continue\n",
    "    did_str = \"\" if pd.isna(did) else str(did)\n",
    "    for tok in splitter.split(str(s)):\n",
    "        if tok and tok != \".\" and tok not in snp2dhs:\n",
    "            snp2dhs[tok] = did_str\n",
    "keep_rsid = set(snp2dhs.keys())\n",
    "print(f\"[info] DHS RSIDs from outcome: {len(keep_rsid):,}\")\n",
    "\n",
    "# ---------- 1) Load GTEx eQTL pairs (only needed columns) ----------\n",
    "eqtl = pd.read_parquet(eqtl_path, columns=[\"variant_id\",\"gene_id\",\"pval_nominal\",\"slope\",\"slope_se\"])\n",
    "print(f\"[info] GTEx WB rows (significant pairs): {len(eqtl):,}\")\n",
    "\n",
    "# Parse alleles and position from variant_id: chr1_1035804_G_A_b38\n",
    "parts = eqtl[\"variant_id\"].str.split(\"_\", expand=True)\n",
    "eqtl[\"chr\"]  = parts[0].str.replace(\"^chr\",\"\",regex=True)\n",
    "eqtl[\"pos\"]  = pd.to_numeric(parts[1], errors=\"coerce\")\n",
    "eqtl[\"ref\"]  = parts[2]\n",
    "eqtl[\"alt\"]  = parts[3]\n",
    "\n",
    "# ---------- 2) Map variant_id → rsid ----------\n",
    "lookup = pd.read_csv(lookup_path, sep=\"\\t\", dtype=\"string\",\n",
    "                     usecols=[\"variant_id\",\"rs_id_dbSNP155_GRCh38p13\"])\n",
    "var2rs = dict(zip(lookup[\"variant_id\"], lookup[\"rs_id_dbSNP155_GRCh38p13\"]))\n",
    "eqtl[\"rsid\"] = eqtl[\"variant_id\"].map(var2rs).astype(\"string\")\n",
    "\n",
    "# Filter to SNPs that are in DHS (by RSID)\n",
    "eqtl = eqtl[eqtl[\"rsid\"].isin(keep_rsid)].copy()\n",
    "print(f\"[info] Rows after DHS RSID filter: {len(eqtl):,}\")\n",
    "\n",
    "# Attach dhs_id\n",
    "eqtl[\"dhs_id\"] = eqtl[\"rsid\"].map(snp2dhs).astype(\"string\")\n",
    "\n",
    "# ---------- 3) Map gene_id → gene_name from GTF ----------\n",
    "def load_gene_map(gtf):\n",
    "    gmap = {}\n",
    "    with open(gtf, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line or line[0] == \"#\": continue\n",
    "            fields = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            if len(fields) < 9 or fields[2] != \"gene\": continue\n",
    "            info = fields[8]\n",
    "            gid = gname = None\n",
    "            for item in info.split(\";\"):\n",
    "                s = item.strip()\n",
    "                if s.startswith(\"gene_id\"):\n",
    "                    gid = s.split('\"')[1]\n",
    "                elif s.startswith(\"gene_name\"):\n",
    "                    gname = s.split('\"')[1]\n",
    "            if gid and gname:\n",
    "                gmap[gid] = gname\n",
    "    return gmap\n",
    "\n",
    "gene_map = load_gene_map(gtf_path)\n",
    "eqtl[\"gene\"] = eqtl[\"gene_id\"].map(gene_map).astype(\"string\")\n",
    "\n",
    "# ---------- 4) Compute Z and reduce to one SNP per (gene, dhs_id) ----------\n",
    "# Effect allele = ALT; other allele = REF (GTEx slope is for ALT vs REF)\n",
    "eqtl[\"effect_allele\"] = eqtl[\"alt\"]\n",
    "eqtl[\"other_allele\"]  = eqtl[\"ref\"]\n",
    "\n",
    "# Numeric conversions\n",
    "eqtl[\"pval_nominal\"] = pd.to_numeric(eqtl[\"pval_nominal\"], errors=\"coerce\")\n",
    "eqtl[\"slope\"]        = pd.to_numeric(eqtl[\"slope\"], errors=\"coerce\")\n",
    "eqtl[\"slope_se\"]     = pd.to_numeric(eqtl[\"slope_se\"], errors=\"coerce\")\n",
    "\n",
    "# Z score (use sign of slope; robust to se=0)\n",
    "eqtl[\"Z\"] = eqtl[\"slope\"] / eqtl[\"slope_se\"]\n",
    "eqtl.loc[~np.isfinite(eqtl[\"Z\"]), \"Z\"] = np.nan  # handle inf/NaN gracefully\n",
    "\n",
    "# Keep rows with a valid dhs_id and gene\n",
    "eqtl = eqtl.dropna(subset=[\"dhs_id\",\"gene\"])\n",
    "\n",
    "# Sort for tie-breaking: lowest p, then largest |Z|, then stable order\n",
    "eqtl = eqtl.sort_values([\"gene\",\"dhs_id\",\"pval_nominal\",\"Z\"],\n",
    "                        ascending=[True, True, True, False])\n",
    "\n",
    "# One SNP per (gene, dhs_id)\n",
    "best = eqtl.groupby([\"gene\",\"dhs_id\"], as_index=False).head(1).copy()\n",
    "print(f\"[info] Final (gene × DHS) picks: {len(best):,}\")\n",
    "\n",
    "# ---------- 5) Build MR-ready table ----------\n",
    "out = best.rename(columns={\n",
    "    \"rsid\": \"SNP\",\n",
    "    \"slope\": \"beta\",\n",
    "    \"slope_se\": \"se\",\n",
    "    \"pval_nominal\": \"pval\",\n",
    "})[[\"SNP\",\"effect_allele\",\"other_allele\",\"beta\",\"se\",\"pval\",\"gene\",\"gene_id\",\"dhs_id\"]]\n",
    "\n",
    "out.to_csv(mr_out, sep=\"\\t\", index=False)\n",
    "print(f\"[done] MR exposure written → {mr_out}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
