{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf13249",
   "metadata": {},
   "source": [
    "# 00 DHS-dbSNP filtering\n",
    "\n",
    "**Origin:** `0_0_processing_dbsnp_within_DHS.ipynb`  \n",
    "**This annotated version was generated on:** 2025-10-13 06:41\n",
    "\n",
    "**What this notebook does (high level):**  \n",
    "- Filter dbSNP variants by DNase I hypersensitive sites (DHS) and annotate regulatory context. Prepares regulatory SNP universe for instrument selection.\n",
    "\n",
    "**How to use:**  \n",
    "1. Review the markdown notes before each code cell.  \n",
    "2. Adjust input/output paths as needed for your environment.  \n",
    "3. Run cell-by-cell to reproduce artifacts for downstream steps.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260dd2f5",
   "metadata": {},
   "source": [
    "**Step 1:** Join/merge datasets to align keys across resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bfb7f-d221-4b3c-a902-9501dcacd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Settings\n",
    "output_dir = \"/mnt/f/0.data/ens_vcf/\"\n",
    "base_url = \"https://ftp.ensembl.org/pub/release-114/variation/vcf/homo_sapiens\"\n",
    "chromosomes = [str(i) for i in range(1, 23)]  # chr1 ~ chr22\n",
    "extensions = [\".vcf.gz\", \".vcf.gz.csi\"]       # download both VCF and CSI\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def download_file(url, dest):\n",
    "    try:\n",
    "        with requests.get(url, stream=True, timeout=30) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(dest, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "        print(f\"Downloaded: {dest}\")\n",
    "        return dest\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {url} ({e})\")\n",
    "        return None\n",
    "\n",
    "# Prepare list of all files to download\n",
    "files_to_download = []\n",
    "for chrom in  chromosomes:\n",
    "    for ext in extensions:\n",
    "        fname = f\"homo_sapiens-chr{chrom}{ext}\"\n",
    "        url = f\"{base_url}/{fname}\"\n",
    "        dest = os.path.join(output_dir, fname)\n",
    "        files_to_download.append((url, dest))\n",
    "\n",
    "# Download with 5 threads\n",
    "max_workers = 5\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    future_to_file = {executor.submit(download_file, url, dest): (url, dest) for url, dest in files_to_download}\n",
    "    for future in as_completed(future_to_file):\n",
    "        url, dest = future_to_file[future]\n",
    "        result = future.result()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c0156",
   "metadata": {},
   "source": [
    "**Step 2:** Load tabular data (summary stats / annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4771702a-d132-4ab1-adc8-3869be415e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_157126/279260058.py:96: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dhs = pd.read_csv(dhs_path, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pybedtools\n",
    "import gzip\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "vcf_dir = \"/mnt/f/0.datasets/ens_vcf/\"\n",
    "dhs_path = \"/mnt/f/0.datasets/dhs/DHS_Index_and_Vocabulary_hg38_WM20190703.txt.gz\"\n",
    "out_dir = \"/mnt/f/0.datasets/ens_vcf_dhs/\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "def vcf_chunk_reader(vcf_path, chunk_size=100000):\n",
    "    buffer = []\n",
    "    with gzip.open(vcf_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            buffer.append(line.strip().split('\\t'))\n",
    "            if len(buffer) == chunk_size:\n",
    "                df = pd.DataFrame(buffer, columns=['chr', 'pos', 'rsid', 'ref', 'alt', 'qual', 'filter', 'info'])\n",
    "                yield df\n",
    "                buffer = []\n",
    "        if buffer:\n",
    "            df = pd.DataFrame(buffer, columns=['chr', 'pos', 'rsid', 'ref', 'alt', 'qual', 'filter', 'info'])\n",
    "            yield df\n",
    "\n",
    "def snps_to_bed(df):\n",
    "    # 'chrom', 'start', 'end', 'rsid', 'POS'\n",
    "    df['pos'] = df['pos'].astype(int)\n",
    "    return df.assign(\n",
    "        start=df['pos'] - 1,\n",
    "        end=df['pos'],\n",
    "        POS=df['pos'],\n",
    "    ).rename(columns={'chr':'chrom'})[['chrom','start','end','rsid','POS']]\n",
    "\n",
    "def dhs_to_bed(dhs_df, chrom, component):\n",
    "    # 'chrom', 'start', 'end', 'identifier'\n",
    "    sub = dhs_df[(dhs_df['Chromosome'] == chrom) & (dhs_df['component'] == component)]\n",
    "    return sub[['Chromosome', 'Start', 'End', 'identifier']].rename(\n",
    "        columns={'Chromosome':'chrom','Start':'start','End':'end'}\n",
    "    )\n",
    "\n",
    "def process_chrom(chrom):\n",
    "    chr_str = str(chrom)\n",
    "    vcf_path = os.path.join(vcf_dir, f\"homo_sapiens-chr{chrom}.vcf.gz\")\n",
    "    out_path = os.path.join(out_dir, f\"rsid_in_DHS_chr{chrom}.tsv\")\n",
    "    out_path_lym = os.path.join(out_dir, f\"rsid_in_DHS_chr{chrom}_lym.tsv\")\n",
    "    out_path_mye = os.path.join(out_dir, f\"rsid_in_DHS_chr{chrom}_mye.tsv\")\n",
    "    \n",
    "    # DHS BEDs for the chromosome\n",
    "    lym_bed = pybedtools.BedTool.from_dataframe(dhs_to_bed(dhs, chr_str, 'Lymphoid'))\n",
    "    mye_bed = pybedtools.BedTool.from_dataframe(dhs_to_bed(dhs, chr_str, 'Myeloid / erythroid'))\n",
    "    \n",
    "    results_lym, results_mye = [], []\n",
    "    \n",
    "    for chunk in vcf_chunk_reader(vcf_path, chunk_size=100000):\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "        snps_bed = pybedtools.BedTool.from_dataframe(snps_to_bed(chunk))\n",
    "        # Intersect with DHS, -wa -wb: report all columns from A (SNP) and B (DHS)\n",
    "        lym_overlap = snps_bed.intersect(lym_bed, wa=True, wb=True)\n",
    "        mye_overlap = snps_bed.intersect(mye_bed, wa=True, wb=True)\n",
    "        \n",
    "        if len(lym_overlap) > 0:\n",
    "            # Columns: snp bed: chrom, start, end, rsid, POS; dhs bed: chrom, start, end, identifier\n",
    "            df_lym = lym_overlap.to_dataframe(names=[\n",
    "                'chr', 'start', 'end', 'rsid', 'POS', 'dhs_chr', 'dhs_start', 'dhs_end', 'identifier'\n",
    "            ])\n",
    "            df_lym['component'] = 'Lymphoid'\n",
    "            results_lym.append(df_lym[['rsid', 'POS', 'component', 'identifier']])\n",
    "        if len(mye_overlap) > 0:\n",
    "            df_mye = mye_overlap.to_dataframe(names=[\n",
    "                'chr', 'start', 'end', 'rsid', 'POS', 'dhs_chr', 'dhs_start', 'dhs_end', 'identifier'\n",
    "            ])\n",
    "            df_mye['component'] = 'Mye_ery'\n",
    "            results_mye.append(df_mye[['rsid', 'POS', 'component', 'identifier']])\n",
    "    \n",
    "    df_lym = pd.concat(results_lym, ignore_index=True) if results_lym else pd.DataFrame(columns=['rsid', 'POS', 'component', 'identifier'])\n",
    "    df_mye = pd.concat(results_mye, ignore_index=True) if results_mye else pd.DataFrame(columns=['rsid', 'POS', 'component', 'identifier'])\n",
    "    df_lym.to_csv(out_path_lym, sep='\\t', index=False)\n",
    "    df_mye.to_csv(out_path_mye, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "# --- Load DHS only once for all workers (top level, so it's pickled for each subprocess)\n",
    "dhs = pd.read_csv(dhs_path, sep='\\t')\n",
    "dhs['identifier'] = dhs['identifier'].astype(str)\n",
    "dhs['Chromosome'] = dhs['seqname'].str.replace('chr', '')\n",
    "dhs['Start'] = dhs['start']\n",
    "dhs['End'] = dhs['end']\n",
    "\n",
    "# --- Run with 6 workers\n",
    "if __name__ == \"__main__\":\n",
    "    with ProcessPoolExecutor(max_workers=6) as executor:\n",
    "        list(executor.map(process_chrom, range(1, 23)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9955c",
   "metadata": {},
   "source": [
    "**Step 3:** Load tabular data (summary stats / annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abf9e01-0b35-4eff-9bf3-15afb58766f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr4.tsv written: 1619196 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr5.tsv written: 1753382 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr6.tsv written: 1959169 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr3.tsv written: 2218744 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr2.tsv written: 2770994 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr1.tsv written: 2974381 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr8.tsv written: 1592383 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr9.tsv written: 1410433 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr7.tsv written: 1830229 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr10.tsv written: 1466773 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr13.tsv written: 945242 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr11.tsv written: 1532595 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr15.tsv written: 1041082 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr14.tsv written: 1108494 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr12.tsv written: 1595557 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr16.tsv written: 1289694 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr21.tsv written: 464370 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr18.tsv written: 718011 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr20.tsv written: 850443 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr17.tsv written: 1304123 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr19.tsv written: 1215188 SNPs.\n",
      "/mnt/f/0.data/ens_vcf_dhs/rsid_in_DHS_chr22.tsv written: 703941 SNPs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out_dir = \"/mnt/f/0.datasets/ens_vcf_dhs/\"\n",
    "\n",
    "def process_chrom(chrom):\n",
    "    chr_str = str(chrom)\n",
    "    out_path = os.path.join(out_dir, f\"rsid_in_DHS_chr{chrom}.tsv\")\n",
    "    out_path_lym = os.path.join(out_dir, f\"rsid_in_DHS_chr{chrom}_lym.tsv\")\n",
    "    out_path_mye = os.path.join(out_dir, f\"rsid_in_DHS_chr{chrom}_mye.tsv\")\n",
    "\n",
    "    df_lym = pd.read_csv(out_path_lym, sep='\\t' ) \n",
    "    df_mye = pd.read_csv(out_path_mye, sep='\\t' )\n",
    "    df_all = pd.concat([df_lym, df_mye], ignore_index=True)\n",
    "    # Merge: for rsid+POS+identifier found in both, assign 'Lym_Mye_ery'\n",
    "    if not df_all.empty:\n",
    "        # group by rsid+POS+identifier, assign merged component\n",
    "        df_all = df_all.groupby(['rsid','POS' ])['component'].agg(\n",
    "                lambda x: 'Lym_Mye_ery' if set(x) == {'Lymphoid','Mye_ery'} else list(x)[0]\n",
    "            ).reset_index()\n",
    "        df_all.to_csv(out_path, sep='\\t', index=False)\n",
    "        print(f\"{out_path} written: {len(df_all)} SNPs.\")\n",
    "    else:\n",
    "        print(f\"{out_path}: No SNPs found.\")\n",
    "\n",
    "# --- Run with 6 workers\n",
    "if __name__ == \"__main__\":\n",
    "    with ProcessPoolExecutor(max_workers=6) as executor:\n",
    "        list(executor.map(process_chrom, range(1, 23)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b412f222",
   "metadata": {},
   "source": [
    "**Step 4:** Load tabular data (summary stats / annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781eb829-4b1e-47cb-b643-7d49abad08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rsid    POS_lym     lym_id    POS_mye     mye_id\n",
      "0  rs1000001430       <NA>       <NA>   50979270  1.2842488\n",
      "1  rs1000001499  189726932   1.785795       <NA>       <NA>\n",
      "2  rs1000001701       <NA>       <NA>  230427541  1.9328719\n",
      "3  rs1000001936       <NA>       <NA>   13769354   1.149772\n",
      "4  rs1000002474  203289853  1.8347732       <NA>       <NA>\n",
      "           rsid    POS_lym     lym_id    POS_mye     mye_id\n",
      "0  rs1000000078   28683172  2.2065748       <NA>       <NA>\n",
      "1  rs1000000696       <NA>       <NA>  191479699   2.811475\n",
      "2  rs1000000724    7694393   2.128576       <NA>       <NA>\n",
      "3  rs1000001129       <NA>       <NA>   31012765  2.2152529\n",
      "4  rs1000001171  157411878   2.684923       <NA>       <NA>\n",
      "           rsid   POS_lym     lym_id   POS_mye     mye_id\n",
      "0  rs1000000393  15384792   3.169858      <NA>       <NA>\n",
      "1  rs1000000694      <NA>       <NA>  71385964  3.4240621\n",
      "2  rs1000001006      <NA>       <NA>  14646662   3.166586\n",
      "3  rs1000001162  16511162  3.1749706      <NA>       <NA>\n",
      "4  rs1000001996      <NA>       <NA>  39006604   3.277066\n",
      "           rsid    POS_lym    lym_id   POS_mye    mye_id\n",
      "0  rs1000000926  145217547  4.787068      <NA>      <NA>\n",
      "1  rs1000000969  105846457  4.600791      <NA>      <NA>\n",
      "2  rs1000001778  110714085  4.623859      <NA>      <NA>\n",
      "3    rs10000039       <NA>      <NA>  35364506  4.267378\n",
      "4  rs1000004494    8229404  4.139023      <NA>      <NA>\n",
      "           rsid    POS_lym     lym_id   POS_mye    mye_id\n",
      "0  rs1000000002  106206404    5.62662      <NA>      <NA>\n",
      "1  rs1000000939  152602139   5.856544      <NA>      <NA>\n",
      "2  rs1000001095       <NA>       <NA>  54607255  5.370761\n",
      "3  rs1000001198  181248435  5.9985688      <NA>      <NA>\n",
      "4  rs1000001295   42990523    5.31321      <NA>      <NA>\n",
      "           rsid   POS_lym     lym_id    POS_mye    mye_id\n",
      "0  rs1000000102  90384029  6.5761757       <NA>      <NA>\n",
      "1  rs1000000300      <NA>       <NA>  159668137  6.941213\n",
      "2  rs1000001068      <NA>       <NA>  149109838  6.885568\n",
      "3  rs1000001137  69542709   6.466379       <NA>      <NA>\n",
      "4  rs1000001786  26234203   6.238245       <NA>      <NA>\n",
      "           rsid    POS_lym     lym_id   POS_mye    mye_id\n",
      "0  rs1000000059  117106550   7.761291      <NA>      <NA>\n",
      "1  rs1000001132       <NA>       <NA>  80134149  7.552476\n",
      "2  rs1000001233    7806469   7.144102      <NA>      <NA>\n",
      "3  rs1000001425   44847106  7.3532653      <NA>      <NA>\n",
      "4  rs1000002183   30275857  7.2710605      <NA>      <NA>\n",
      "           rsid   POS_lym     lym_id    POS_mye    mye_id\n",
      "0  rs1000000362  20298980   8.225928       <NA>      <NA>\n",
      "1  rs1000000556      <NA>       <NA>   53873016  8.434141\n",
      "2  rs1000000738      <NA>       <NA>    7052160  8.143868\n",
      "3  rs1000000753      <NA>       <NA>  110085997   8.78254\n",
      "4  rs1000002675  73382248  8.5550729       <NA>      <NA>\n",
      "           rsid   POS_lym    lym_id    POS_mye     mye_id\n",
      "0  rs1000000176  22067334  9.243489       <NA>       <NA>\n",
      "1  rs1000000620      <NA>      <NA>  100641032   9.754294\n",
      "2  rs1000003563      <NA>      <NA>  123335351  9.9020604\n",
      "3  rs1000004370  94204687  9.712498       <NA>       <NA>\n",
      "4  rs1000007344  97363337  9.733073       <NA>       <NA>\n",
      "           rsid   POS_lym      lym_id    POS_mye     mye_id\n",
      "0  rs1000000174      <NA>        <NA>  113867079  10.865688\n",
      "1  rs1000000404  57663008   10.487696       <NA>       <NA>\n",
      "2  rs1000001814  52558340     10.4534       <NA>       <NA>\n",
      "3  rs1000002331   7492515  10.1502949       <NA>       <NA>\n",
      "4  rs1000002525  24724156   10.266244       <NA>       <NA>\n",
      "           rsid    POS_lym      lym_id   POS_mye      mye_id\n",
      "0  rs1000000453  109279100   11.828076      <NA>        <NA>\n",
      "1  rs1000001494  122675379  11.9172605      <NA>        <NA>\n",
      "2  rs1000002574       <NA>        <NA>  78339521    11.62197\n",
      "3  rs1000002937       <NA>        <NA>  32415094  11.3160606\n",
      "4  rs1000003082   65146828  11.5340841      <NA>        <NA>\n",
      "           rsid    POS_lym     lym_id    POS_mye     mye_id\n",
      "0  rs1000000516       <NA>       <NA>   85514651  12.677479\n",
      "1  rs1000000563  101839184  12.787672       <NA>       <NA>\n",
      "2  rs1000001009  117667403  12.894468       <NA>       <NA>\n",
      "3  rs1000002241       <NA>       <NA>   71645514  12.583862\n",
      "4  rs1000002660       <NA>       <NA>  108936852   12.83556\n",
      "           rsid   POS_lym     lym_id   POS_mye      mye_id\n",
      "0  rs1000001654      <NA>       <NA>  55526333   13.536884\n",
      "1  rs1000003064      <NA>       <NA>  80067378   13.730029\n",
      "2  rs1000004281  39919849  13.414081      <NA>        <NA>\n",
      "3  rs1000004720      <NA>       <NA>  80890225  13.7364917\n",
      "4  rs1000006607  51820652  13.507818      <NA>        <NA>\n",
      "           rsid   POS_lym      lym_id   POS_mye     mye_id\n",
      "0  rs1000001572      <NA>        <NA>  96738016  14.913117\n",
      "1  rs1000001830  32659263    14.37457      <NA>       <NA>\n",
      "2  rs1000002134  50530761  14.5246888      <NA>       <NA>\n",
      "3  rs1000002337      <NA>        <NA>  91774882   14.87149\n",
      "4  rs1000002913      <NA>        <NA>  30652118  14.357679\n",
      "           rsid   POS_lym     lym_id   POS_mye     mye_id\n",
      "0  rs1000004640  28150073  15.348446      <NA>       <NA>\n",
      "1  rs1000005880      <NA>       <NA>  65677989   15.67943\n",
      "2  rs1000005969      <NA>       <NA>  56471926  15.598283\n",
      "3  rs1000006164      <NA>       <NA>  56184815   15.59585\n",
      "4  rs1000006270      <NA>       <NA>  93587064  15.925865\n",
      "           rsid   POS_lym     lym_id   POS_mye     mye_id\n",
      "0  rs1000001066      <NA>       <NA>  62209189   16.71976\n",
      "1  rs1000001490  46976116  16.568021      <NA>       <NA>\n",
      "2  rs1000002303  22206676  16.321326      <NA>       <NA>\n",
      "3  rs1000002733      <NA>       <NA>  51814983  16.616195\n",
      "4  rs1000003040    693954  16.106981      <NA>       <NA>\n",
      "           rsid   POS_lym     lym_id   POS_mye     mye_id\n",
      "0  rs1000000581      <NA>       <NA>  69907253  17.855503\n",
      "1  rs1000002842   4360246  17.147162      <NA>       <NA>\n",
      "2  rs1000003213      <NA>       <NA>  67354360  17.827786\n",
      "3  rs1000003367  75260882  17.913335      <NA>       <NA>\n",
      "4  rs1000003453      <NA>       <NA>  73319062  17.892343\n",
      "           rsid   POS_lym    lym_id   POS_mye     mye_id\n",
      "0  rs1000004091      <NA>      <NA>  34988607  18.491618\n",
      "1  rs1000004110  62729761  18.80222      <NA>       <NA>\n",
      "2  rs1000004806      <NA>      <NA>  56825556  18.736205\n",
      "3  rs1000005770  38403857  18.53009      <NA>       <NA>\n",
      "4  rs1000006755      <NA>      <NA>  38363003   18.52949\n",
      "           rsid   POS_lym     lym_id   POS_mye     mye_id\n",
      "0  rs1000000222  47232491  19.824978      <NA>       <NA>\n",
      "1  rs1000001244   3053303   19.14696      <NA>       <NA>\n",
      "2  rs1000002352      <NA>       <NA>  49870494  19.865326\n",
      "3  rs1000002876   8457897  19.229836      <NA>       <NA>\n",
      "4  rs1000003678  16543754  19.353976      <NA>       <NA>\n",
      "           rsid   POS_lym    lym_id   POS_mye     mye_id\n",
      "0  rs1000001216  61401206  20.95714      <NA>       <NA>\n",
      "1  rs1000001877      <NA>      <NA>  62465603  20.972003\n",
      "2  rs1000003333      <NA>      <NA>   3082498  20.143064\n",
      "3  rs1000003584  61643429  20.96037      <NA>       <NA>\n",
      "4  rs1000004235      <NA>      <NA>  33651648  20.569724\n",
      "           rsid   POS_lym     lym_id   POS_mye     mye_id\n",
      "0  rs1000000431  41321285  21.896053      <NA>       <NA>\n",
      "1  rs1000000548      <NA>       <NA>  26274655   21.60639\n",
      "2  rs1000001509      <NA>       <NA>  33247760   21.74045\n",
      "3  rs1000002171      <NA>       <NA>  34914598  21.772596\n",
      "4  rs1000004130  14602796   21.38138      <NA>       <NA>\n",
      "           rsid   POS_lym     lym_id   POS_mye    mye_id\n",
      "0  rs1000000683  36376772  22.743639      <NA>      <NA>\n",
      "1  rs1000001181  39939046  22.806691      <NA>      <NA>\n",
      "2  rs1000002129  38842385  22.787321      <NA>      <NA>\n",
      "3  rs1000002521      <NA>       <NA>  36983923  22.75439\n",
      "4  rs1000003454  41928787  22.842049      <NA>      <NA>\n",
      "[done] Wrote 32,364,424 rows → /mnt/f/0.datasets/ens_vcf_dhs/rsid_in_DHS_merged_lym_mye.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% Merge rsid_in_DHS_chr{n}_{lym|mye}.tsv into one table\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "in_dir  = \"/mnt/f/0.datasets/ens_vcf_dhs/chroms/\"\n",
    "out_dir = \"/mnt/f/0.datasets/ens_vcf_dhs/\"\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_side(path, id_colname):\n",
    "    \"\"\"Load one of (lym/mye) files with robust parsing; keep first occurrence per rsid.\"\"\"\n",
    "    if not Path(path).exists():\n",
    "        return pd.DataFrame(columns=[\"rsid\",\"POS\",id_colname])\n",
    "    df = pd.read_csv(\n",
    "        path, sep=r\"\\s+|,\", engine=\"python\",\n",
    "        usecols=[\"rsid\",\"POS\",\"identifier\"],\n",
    "        dtype={\"rsid\":\"string\",\"POS\":\"Int64\",\"identifier\":\"string\"}\n",
    "    ).dropna(subset=[\"rsid\"])\n",
    "    df = df.drop_duplicates(subset=[\"rsid\"], keep=\"first\")\n",
    "    df = df.rename(columns={\"identifier\": id_colname})\n",
    "    return df[[\"rsid\",\"POS\",id_colname]]\n",
    "\n",
    "merged_chunks = []\n",
    "warnings_pos_mismatch = 0\n",
    "\n",
    "for chrom in range(1, 23):\n",
    "    p_lym = os.path.join(in_dir, f\"rsid_in_DHS_chr{chrom}_lym.tsv\")\n",
    "    p_mye = os.path.join(in_dir, f\"rsid_in_DHS_chr{chrom}_mye.tsv\")\n",
    "\n",
    "    df_lym = load_side(p_lym, \"lym_id\")\n",
    "    df_mye = load_side(p_mye, \"mye_id\")\n",
    "\n",
    "    if df_lym.empty and df_mye.empty:\n",
    "        continue\n",
    "\n",
    "    # Outer-join on rsid\n",
    "    m = pd.merge(df_lym, df_mye, on=\"rsid\", how=\"outer\", suffixes=(\"_lym\",\"_mye\"))\n",
    "\n",
    "    print( m.head() ) \n",
    "    # Choose POS: prefer lymphoid POS when both present, otherwise use the available one\n",
    "    # Track mismatches (optional)\n",
    "    both_pos = m[\"POS_lym\"].notna() & m[\"POS_mye\"].notna()\n",
    "    if both_pos.any():\n",
    "        warnings_pos_mismatch += int((m.loc[both_pos, \"POS_lym\"] != m.loc[both_pos, \"POS_mye\"]).sum())\n",
    "\n",
    "    m[\"POS\"] = m[\"POS_lym\"].combine_first(m[\"POS_mye\"]).astype(\"Int64\")\n",
    "    m = m.drop(columns=[\"POS_lym\",\"POS_mye\"])\n",
    "\n",
    "    # Component label\n",
    "    has_lym = m[\"lym_id\"].notna()\n",
    "    has_mye = m[\"mye_id\"].notna()\n",
    "    m[\"component\"] = np.where(has_lym & has_mye, \"lym_mye\",\n",
    "                         np.where(has_lym, \"lym\",\n",
    "                           np.where(has_mye, \"mye\", \"\")))\n",
    "\n",
    "    # Add CHROM\n",
    "    m.insert(0, \"CHROM\", chrom)\n",
    "\n",
    "    # Reorder columns\n",
    "    m = m[[\"CHROM\",\"POS\",\"rsid\",\"component\",\"lym_id\",\"mye_id\"]]\n",
    "\n",
    "    merged_chunks.append(m)\n",
    "\n",
    "# Concatenate all chromosomes\n",
    "if merged_chunks:\n",
    "    merged = pd.concat(merged_chunks, ignore_index=True)\n",
    "else:\n",
    "    merged = pd.DataFrame(columns=[\"CHROM\",\"POS\",\"rsid\",\"component\",\"lym_id\",\"mye_id\"])\n",
    "\n",
    "# (Optional) report POS mismatches when rsid appeared in both files\n",
    "if warnings_pos_mismatch:\n",
    "    print(f\"[WARN] {warnings_pos_mismatch} rsids had different POS between lym and mye; \"\n",
    "          \"kept lymphoid POS when available.\")\n",
    "\n",
    "# Write output\n",
    "out_path = os.path.join(out_dir, \"rsid_in_DHS_merged_lym_mye.tsv\")\n",
    "merged.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "print(f\"[done] Wrote {len(merged):,} rows → {out_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0396d0d-f013-4c99-91bf-b14caf0ffcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93309b70",
   "metadata": {},
   "source": [
    "**Step 6:** Run a processing or analysis step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126f387-5fb4-4a96-9c10-3de8b3d4ea9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23b2f57c",
   "metadata": {},
   "source": [
    "**Step 7:** Run a processing or analysis step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98d7cb-aa0f-41cd-818e-0845b956c705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3827230a",
   "metadata": {},
   "source": [
    "**Step 8:** Run a processing or analysis step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a55fb6-42f8-4bec-8940-2666f1c30f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010477438792191151"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "498/( 2043+ 473264)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64c394",
   "metadata": {},
   "source": [
    "**Step 9:** Run a processing or analysis step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
